{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“š Prerequisites\n",
    "\n",
    "Ensure that your Azure Services are properly set up, your Conda environment is created, and your environment variables are configured as per the instructions in the [SETTINGS.md](SETTINGS.md) file.\n",
    "\n",
    "## ðŸ“‹ Table of Contents\n",
    "\n",
    "This notebook assists in testing and retrieving the headers of Azure OpenAI, covering the following sections:\n",
    "\n",
    "1. [**Setting Up Azure OpenAI Client**](#setting-up-azure-openai-client): Outlines the process of initializing the Azure OpenAI client.\n",
    "\n",
    "2. [**Calling Azure OpenAI API**](#calling-azure-openai-api): Discusses how to make API calls to Azure OpenAI.\n",
    "\n",
    "3. [**Extracting Headers and Payload Metadata**](#extracting-headers-and-payload-metadata): Explores how to extract headers and payload metadata from the API response.\n",
    "\n",
    "4. [**Analyzing Rate Limit Info**](#analyzing-rate-limit-info): Details the steps to analyze the rate limit information from the API response.\n",
    "\n",
    "For additional information, refer to the following resources:\n",
    "- [AOAI API Documentation](https://learn.microsoft.com/en-us/azure/ai-services/openai/reference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory changed to C:\\Users\\pablosal\\Desktop\\gbbai-azure-aoai-faq\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Define the target directory\n",
    "target_directory = (\n",
    "    r\"C:\\Users\\pablosal\\Desktop\\gbbai-azure-aoai-faq\"  # change your directory here\n",
    ")\n",
    "\n",
    "# Check if the directory exists\n",
    "if os.path.exists(target_directory):\n",
    "    # Change the current working directory\n",
    "    os.chdir(target_directory)\n",
    "    print(f\"Directory changed to {os.getcwd()}\")\n",
    "else:\n",
    "    print(f\"Directory {target_directory} does not exist.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the libraries\n",
    "from dotenv import load_dotenv\n",
    "from src.aoai.azure_openai import AzureOpenAIManager\n",
    "from typing import Dict, Optional\n",
    "from requests import Response\n",
    "import requests\n",
    "\n",
    "from utils.ml_logging import get_logger\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "# Set up logger\n",
    "logger = get_logger()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Up Azure OpenAI Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the client. You can find it in src/aoai/azure_openai.py.\n",
    "# It is essentially a wrapper using dependency injection to automate the initialization\n",
    "# and most used API calls.\n",
    "azure_openai_client = AzureOpenAIManager()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calling Azure OpenAI API\n",
    "\n",
    "### Creating Helper Function\n",
    "This function is designed to extract and build the metadata in JSON format. It's particularly useful for extracting rate limit and usage information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_rate_limit_and_usage_info(response: Response) -> Dict[str, Optional[int]]:\n",
    "    \"\"\"\n",
    "    Extracts rate limiting information from the Azure Open API response headers and usage information from the payload.\n",
    "\n",
    "    :param response: The response object returned by a requests call.\n",
    "    :return: A dictionary containing the remaining requests, remaining tokens, and usage information\n",
    "             including prompt tokens, completion tokens, and total tokens.\n",
    "    \"\"\"\n",
    "    headers = response.headers\n",
    "    usage = response.json().get(\"usage\", {})\n",
    "    return {\n",
    "        \"remaining-requests\": headers.get(\"x-ratelimit-remaining-requests\"),\n",
    "        \"remaining-tokens\": headers.get(\"x-ratelimit-remaining-tokens\"),\n",
    "        \"prompt-tokens\": usage.get(\"prompt_tokens\"),\n",
    "        \"completion_tokens\": usage.get(\"completion_tokens\"),\n",
    "        \"total_tokens\": usage.get(\"total_tokens\"),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encapsulating Completions API Calls into a Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_azure_openai_chat_completions_api(\n",
    "    deployment_id: str, method: str, body: dict = None, api_version: str = \"2023-11-01\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Calls the Azure OpenAI API with the given parameters.\n",
    "\n",
    "    :param deployment_id: The ID of the deployment to access.\n",
    "    :param method: The HTTP method to use (\"get\" or \"post\").\n",
    "    :param body: The body of the request for \"post\" method. Defaults to None.\n",
    "    :param api_version: The API version to use. Defaults to \"2023-11-01\".\n",
    "\n",
    "    :return: The status code and response from the API call, along with rate limit headers.\n",
    "    \"\"\"\n",
    "    if method.lower() not in [\"get\", \"post\"]:\n",
    "        logger.error(\"Invalid HTTP method. Expected 'get' or 'post'.\")\n",
    "        return None, None, {}\n",
    "\n",
    "    url = f\"{azure_openai_client.azure_endpoint}/openai/deployments/{deployment_id}/chat/completions?api-version={api_version}\"\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"api-key\": azure_openai_client.api_key,\n",
    "        \"x-ms-useragent\": \"aoai-benchmark\"\n",
    "    }\n",
    "\n",
    "    with requests.Session() as session:\n",
    "        session.headers.update(headers)\n",
    "\n",
    "        try:\n",
    "            if method.lower() == \"get\":\n",
    "                response = session.get(url)\n",
    "            else:  # method.lower() == \"post\"\n",
    "                response = session.post(url, json=body)\n",
    "            response.raise_for_status()  # Raises HTTPError for bad responses\n",
    "        except requests.HTTPError as http_err:\n",
    "            logger.error(f\"HTTP error occurred: {http_err}\")\n",
    "            return response.status_code, http_err.response.json(), {}\n",
    "        except Exception as err:\n",
    "            logger.error(f\"An error occurred: {err}\")\n",
    "            return None, None, {}\n",
    "\n",
    "    # Extract rate limit headers and usage details\n",
    "    rate_limit_headers = extract_rate_limit_and_usage_info(response)\n",
    "    print(response.headers)\n",
    "    return response.status_code, response.json(), rate_limit_headers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting Headers and Payload Metadata\n",
    "\n",
    "#### Constructing the Request\n",
    "\n",
    "- **max_tokens**: Optional. Integer specifying the maximum number of tokens to generate. Default is 24.\n",
    "- **temperature**: Optional. Number between 0 and 2 indicating the sampling temperature. Default is 1.\n",
    "- **top_p**: Optional. Nucleus sampling parameter as a number between 0 and 1. Default is 1.\n",
    "- **user**: Optional. A unique identifier for the end-user to help monitor and detect abuse.\n",
    "- **n**: Optional. Integer for the number of completions to generate for each prompt. Default is 1.\n",
    "- **presence_penalty**: Optional. Number between -2.0 and 2.0 to penalize new tokens based on presence in the text so far. Default is 0.\n",
    "- **frequency_penalty**: Optional. Number between -2.0 and 2.0 to penalize new tokens based on frequency in the text so far. Default is 0.\n",
    "- **messages**: Optional. An array of message objects.\n",
    "\n",
    "You can learn more about the aoai API  [official documentation](https://learn.microsoft.com/en-us/azure/ai-services/openai/reference)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "body = {\n",
    "    \"max_tokens\": 24,\n",
    "    \"temperature\": 1,\n",
    "    \"top_p\": 1,\n",
    "    \"user\": \"\",\n",
    "    \"n\": 1,\n",
    "    \"presence_penalty\": 0,\n",
    "    \"frequency_penalty\": 0,\n",
    "    \"messages\": [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Does Azure OpenAI support customer managed keys?\"},\n",
    "        {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": \"Yes, customer managed keys are supported by Azure OpenAI.\",\n",
    "        },\n",
    "        {\"role\": \"user\", \"content\": \"Do other Azure AI services support this too?\"},\n",
    "        {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": \"Yes, other Azure AI services also support customer managed keys.\",\n",
    "        },\n",
    "        {\"role\": \"user\", \"content\": \"Can you tell me more about these services?\"},\n",
    "        {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": \"Sure, Azure AI services include Azure Cognitive Services, Azure Machine Learning, and more.\",\n",
    "        },\n",
    "        {\"role\": \"user\", \"content\": \"What is Azure Cognitive Services?\"},\n",
    "        {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": \"Azure Cognitive Services is a collection of APIs and services for building intelligent applications.\",\n",
    "        },\n",
    "        {\"role\": \"user\", \"content\": \"What is Azure Machine Learning?\"},\n",
    "        {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": \"Azure Machine Learning is a cloud-based service for building, training, and deploying machine learning models.\",\n",
    "        },\n",
    "        {\"role\": \"user\", \"content\": \"Thank you for the information.\"},\n",
    "        {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": \"You're welcome! If you have any other questions, feel free to ask.\",\n",
    "        },\n",
    "        {\"role\": \"user\", \"content\": \"What other services does Azure offer?\"},\n",
    "        {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": \"Azure offers a wide range of services including computing, analytics, storage, and networking.\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Can you tell me more about Azure's computing services?\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": \"Azure's computing services include virtual machines, container services, and serverless computing.\",\n",
    "        },\n",
    "        {\"role\": \"user\", \"content\": \"What is serverless computing?\"},\n",
    "        {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": \"Serverless computing is a cloud computing model where the cloud provider automatically manages the provisioning and scaling of servers.\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"That's interesting. Thank you for the information.\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": \"You're welcome! If you have any other questions, feel free to ask.\",\n",
    "        },\n",
    "    ],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Cache-Control': 'no-cache, must-revalidate', 'Content-Length': '428', 'Content-Type': 'application/json', 'access-control-allow-origin': '*', 'apim-request-id': 'a4c6189e-8b0f-4a49-bf03-343bfe7c87f8', 'Strict-Transport-Security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'x-ms-region': 'Canada East', 'x-ratelimit-remaining-requests': '9', 'x-ratelimit-remaining-tokens': '9629', 'x-accel-buffering': 'no', 'x-request-id': '6e7347f6-69db-480e-bf5b-934cf5130d7b', 'x-ms-client-request-id': 'a4c6189e-8b0f-4a49-bf03-343bfe7c87f8', 'azureml-model-session': 'd018-20240201032837', 'Date': 'Fri, 02 Feb 2024 05:13:43 GMT'}\n",
      "Status Code: 200\n",
      "Response: {'id': 'chatcmpl-8ng9sFt76UntMD7xLTfd29Ql4dbJA', 'object': 'chat.completion', 'created': 1706850820, 'model': 'gpt-4', 'choices': [{'finish_reason': 'length', 'index': 0, 'message': {'role': 'assistant', 'content': \"You're welcome! If you have any more questions or need further clarification on any topic, feel free to reach out.\"}}], 'usage': {'prompt_tokens': 333, 'completion_tokens': 24, 'total_tokens': 357}, 'system_fingerprint': 'fp_68a7d165bf'}\n",
      "Rate Limit Info: {'remaining-requests': '9', 'remaining-tokens': '9629', 'prompt-tokens': 333, 'completion_tokens': 24, 'total_tokens': 357}\n"
     ]
    }
   ],
   "source": [
    "status_code, response, rate_limit_info = call_azure_openai_chat_completions_api(\n",
    "    deployment_id=azure_openai_client.chat_model_name,\n",
    "    method=\"post\",\n",
    "    body=body,\n",
    "    api_version=\"2023-05-15\",\n",
    ")\n",
    "\n",
    "# Print the status code, response, and rate limit info\n",
    "print(\"Status Code:\", status_code)\n",
    "print(\"Response:\", response)\n",
    "print(\"Rate Limit Info:\", rate_limit_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing Rate Limit Info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rate limit information provides details about the usage of the API:\n",
    "\n",
    "- **Remaining Requests**: The number of API calls that can still be made. In this case, there are 9 requests left.\n",
    "- **Remaining Tokens**: The number of tokens that can still be generated. In this case, there are 9258 tokens left.\n",
    "- **Prompt Tokens**: The number of tokens used in the prompt for this API call. In this case, 333 tokens were used.\n",
    "- **Completion Tokens**: The number of tokens generated in the completion for this API call. In this case, 24 tokens were generated.\n",
    "- **Total Tokens**: The total number of tokens used in this API call. This is the sum of the prompt tokens and the completion tokens. In this case, 357 tokens were used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus: Programmatically Stop Call if Input Tokens Exceed Limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_RETRY_SECONDS = 5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple, Dict, Any, Optional, Union\n",
    "import backoff\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _terminal_http_code(e) -> bool:\n",
    "    \"\"\"\n",
    "    Determine whether to give up retrying based on the HTTP status code.\n",
    "    \"\"\"\n",
    "    # Assuming e is an exception instance from the requests library.\n",
    "    status_code = e.response.status_code\n",
    "    if status_code == 429:\n",
    "        logger.info(f\"429 status code received, will retry. Error: {e}\")\n",
    "    else:\n",
    "        logger.info(f\"Non-retryable status code {status_code} received. Error: {e}\")\n",
    "    return status_code != 429\n",
    "\n",
    "def backoff_hdlr(details):\n",
    "    \"\"\"\n",
    "    Log details when a backoff occurs.\n",
    "    \"\"\"\n",
    "    logger.warning(f\"Backing off {details['wait']:0.1f} seconds after {details['tries']} tries calling function {details['target']} with args {details['args']} and kwargs {details['kwargs']}\")\n",
    "\n",
    "def giveup_hdlr(details):\n",
    "    \"\"\"\n",
    "    Log details when giving up on retries.\n",
    "    \"\"\"\n",
    "    logger.warning(f\"Giving up after {details['tries']} tries calling function {details['target']} with args {details['args']} and kwargs {details['kwargs']}\")\n",
    "\n",
    "@backoff.on_exception(backoff.expo,\n",
    "                   (requests.exceptions.RequestException),\n",
    "                    jitter=backoff.full_jitter,\n",
    "                    max_time=MAX_RETRY_SECONDS,\n",
    "                    giveup=_terminal_http_code,\n",
    "                    on_backoff=backoff_hdlr,\n",
    "                    on_giveup=giveup_hdlr)\n",
    "def call_azure_openai_chat_completions_api_with_pre_check(\n",
    "    deployment_id: str,\n",
    "    method: str,\n",
    "    body: Optional[Dict[str, Any]] = None,\n",
    "    api_version: str = \"2023-11-01\",\n",
    ") -> Tuple[Optional[int], Optional[Union[Dict[str, Any], str]], Dict[str, str]]:\n",
    "    if method.lower() not in [\"get\", \"post\"]:\n",
    "        logger.error(\"Invalid HTTP method. Expected 'get' or 'post'.\")\n",
    "        return None, \"Invalid HTTP method. Expected 'get' or 'post'.\", {}\n",
    "\n",
    "    start_time = time.time()\n",
    "    while time.time() - start_time < MAX_RETRY_SECONDS:\n",
    "        (\n",
    "            status_code,\n",
    "            response,\n",
    "            rate_limit_headers,\n",
    "        ) = call_azure_openai_chat_completions_api(\n",
    "            deployment_id, method=method, body=body, api_version=api_version)\n",
    "        if status_code != 429:\n",
    "            break\n",
    "        time.sleep(1)  # sleep for a while before retrying\n",
    "\n",
    "    return status_code, response, rate_limit_headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Cache-Control': 'no-cache, must-revalidate', 'Content-Length': '440', 'Content-Type': 'application/json', 'access-control-allow-origin': '*', 'apim-request-id': '31f1547c-6acb-4166-bb2a-bf9a97b997bf', 'Strict-Transport-Security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'x-ms-region': 'Canada East', 'x-ratelimit-remaining-requests': '6', 'x-ratelimit-remaining-tokens': '8516', 'x-accel-buffering': 'no', 'x-request-id': 'f1274dd1-f361-442b-b488-1725f9b63cda', 'x-ms-client-request-id': '31f1547c-6acb-4166-bb2a-bf9a97b997bf', 'azureml-model-session': 'd017-20240201023444', 'Date': 'Fri, 02 Feb 2024 05:35:26 GMT'}\n",
      "{'Cache-Control': 'no-cache, must-revalidate', 'Content-Length': '428', 'Content-Type': 'application/json', 'access-control-allow-origin': '*', 'apim-request-id': '2ea9f880-60b3-4899-8120-f6455f64f71e', 'Strict-Transport-Security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'x-ms-region': 'Canada East', 'x-ratelimit-remaining-requests': '9', 'x-ratelimit-remaining-tokens': '9629', 'x-accel-buffering': 'no', 'x-request-id': 'ddbb54ae-378d-4b49-8b54-a500ad0d32b4', 'x-ms-client-request-id': '2ea9f880-60b3-4899-8120-f6455f64f71e', 'azureml-model-session': 'd016-20240201014049', 'Date': 'Fri, 02 Feb 2024 05:35:26 GMT'}\n",
      "{'Cache-Control': 'no-cache, must-revalidate', 'Content-Length': '416', 'Content-Type': 'application/json', 'access-control-allow-origin': '*', 'apim-request-id': 'd2f2afef-07b9-4649-b6ea-11b3fc775c8d', 'Strict-Transport-Security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'x-ms-region': 'Canada East', 'x-ratelimit-remaining-requests': '4', 'x-ratelimit-remaining-tokens': '7774', 'x-accel-buffering': 'no', 'x-request-id': '2bafd465-8a8a-473e-8a2c-d9c36ad9018a', 'x-ms-client-request-id': 'd2f2afef-07b9-4649-b6ea-11b3fc775c8d', 'azureml-model-session': 'd017-20240201023444', 'Date': 'Fri, 02 Feb 2024 05:35:27 GMT'}\n",
      "{'Cache-Control': 'no-cache, must-revalidate', 'Content-Length': '421', 'Content-Type': 'application/json', 'access-control-allow-origin': '*', 'apim-request-id': 'd38c110f-b805-4a50-8e6c-65d64cdcfca0', 'Strict-Transport-Security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'x-ms-region': 'Canada East', 'x-ratelimit-remaining-requests': '4', 'x-ratelimit-remaining-tokens': '7774', 'x-accel-buffering': 'no', 'x-request-id': '68bab1d0-77b9-4447-b212-56e2d3e90341', 'x-ms-client-request-id': 'd38c110f-b805-4a50-8e6c-65d64cdcfca0', 'azureml-model-session': 'd018-20240201032837', 'Date': 'Fri, 02 Feb 2024 05:35:26 GMT'}\n",
      "{'Cache-Control': 'no-cache, must-revalidate', 'Content-Length': '425', 'Content-Type': 'application/json', 'access-control-allow-origin': '*', 'apim-request-id': '46b9b24a-796a-41b1-8e07-74afad7d0ad2', 'Strict-Transport-Security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'x-ms-region': 'Canada East', 'x-ratelimit-remaining-requests': '4', 'x-ratelimit-remaining-tokens': '7774', 'x-accel-buffering': 'no', 'x-request-id': 'eca5d4ff-c23d-441c-9b77-8967b4a9d39f', 'x-ms-client-request-id': '46b9b24a-796a-41b1-8e07-74afad7d0ad2', 'azureml-model-session': 'd016-20240201014049', 'Date': 'Fri, 02 Feb 2024 05:35:26 GMT'}\n",
      "{'Cache-Control': 'no-cache, must-revalidate', 'Content-Length': '452', 'Content-Type': 'application/json', 'access-control-allow-origin': '*', 'apim-request-id': 'e41c5e57-c229-4e23-857e-f1ba8c3fbb87', 'Strict-Transport-Security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'x-ms-region': 'Canada East', 'x-ratelimit-remaining-requests': '8', 'x-ratelimit-remaining-tokens': '9258', 'x-accel-buffering': 'no', 'x-request-id': '42556ec6-1bd7-4720-aa1a-6c8a2b4a4951', 'x-ms-client-request-id': 'e41c5e57-c229-4e23-857e-f1ba8c3fbb87', 'azureml-model-session': 'd017-20240201023444', 'Date': 'Fri, 02 Feb 2024 05:35:26 GMT'}\n",
      "{'Cache-Control': 'no-cache, must-revalidate', 'Content-Length': '421', 'Content-Type': 'application/json', 'access-control-allow-origin': '*', 'apim-request-id': 'da5eb95d-99a4-42d2-ac1b-e961e2c2cf49', 'Strict-Transport-Security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'x-ms-region': 'Canada East', 'x-ratelimit-remaining-requests': '8', 'x-ratelimit-remaining-tokens': '9258', 'x-accel-buffering': 'no', 'x-request-id': '2d7ed789-ac8f-42bc-ad2c-0fb077a000dd', 'x-ms-client-request-id': 'da5eb95d-99a4-42d2-ac1b-e961e2c2cf49', 'azureml-model-session': 'd017-20240201023444', 'Date': 'Fri, 02 Feb 2024 05:35:27 GMT'}\n",
      "{'Cache-Control': 'no-cache, must-revalidate', 'Content-Length': '433', 'Content-Type': 'application/json', 'access-control-allow-origin': '*', 'apim-request-id': '8fa32295-bd5b-4ecb-a340-afcaa042fdc9', 'Strict-Transport-Security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'x-ms-region': 'Canada East', 'x-ratelimit-remaining-requests': '7', 'x-ratelimit-remaining-tokens': '8887', 'x-accel-buffering': 'no', 'x-request-id': '1645b989-e48b-464c-b417-33c501017bae', 'x-ms-client-request-id': '8fa32295-bd5b-4ecb-a340-afcaa042fdc9', 'azureml-model-session': 'd016-20240201014049', 'Date': 'Fri, 02 Feb 2024 05:35:26 GMT'}\n",
      "{'Cache-Control': 'no-cache, must-revalidate', 'Content-Length': '434', 'Content-Type': 'application/json', 'access-control-allow-origin': '*', 'apim-request-id': 'd76c495d-2826-456b-8cc0-3f7defce4f1c', 'Strict-Transport-Security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'x-ms-region': 'Canada East', 'x-ratelimit-remaining-requests': '8', 'x-ratelimit-remaining-tokens': '9258', 'x-accel-buffering': 'no', 'x-request-id': '8cfaba05-1fc7-4d15-a962-bbc4d31660f3', 'x-ms-client-request-id': 'd76c495d-2826-456b-8cc0-3f7defce4f1c', 'azureml-model-session': 'd023-20240201080125', 'Date': 'Fri, 02 Feb 2024 05:35:26 GMT'}\n",
      "{'Cache-Control': 'no-cache, must-revalidate', 'Content-Length': '433', 'Content-Type': 'application/json', 'access-control-allow-origin': '*', 'apim-request-id': '9591fa95-b1de-4101-bae2-b7baf7b08e10', 'Strict-Transport-Security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'x-ms-region': 'Canada East', 'x-ratelimit-remaining-requests': '8', 'x-ratelimit-remaining-tokens': '9258', 'x-accel-buffering': 'no', 'x-request-id': '3136b1ca-bd2b-44a9-96a2-0d2b98812c86', 'x-ms-client-request-id': '9591fa95-b1de-4101-bae2-b7baf7b08e10', 'azureml-model-session': 'd018-20240201032837', 'Date': 'Fri, 02 Feb 2024 05:35:28 GMT'}\n",
      "(200, {'id': 'chatcmpl-8ngUwI7ODOdbXeOSYmWRa9Z7YlTPA', 'object': 'chat.completion', 'created': 1706852126, 'model': 'gpt-4', 'choices': [{'finish_reason': 'stop', 'index': 0, 'message': {'role': 'assistant', 'content': \"If you have further questions or need assistance with another topic, feel free to ask. I'm here to help!\"}}], 'usage': {'prompt_tokens': 333, 'completion_tokens': 23, 'total_tokens': 356}, 'system_fingerprint': 'fp_68a7d165bf'}, {'remaining-requests': '4', 'remaining-tokens': '7774', 'prompt-tokens': 333, 'completion_tokens': 23, 'total_tokens': 356})\n",
      "(200, {'id': 'chatcmpl-8ngUwLZX9ApB0hFNaj6asECP6TyYq', 'object': 'chat.completion', 'created': 1706852126, 'model': 'gpt-4', 'choices': [{'finish_reason': 'length', 'index': 0, 'message': {'role': 'assistant', 'content': \"You're welcome! If you have any more questions or need further assistance, feel free to reach out. I'm here\"}}], 'usage': {'prompt_tokens': 333, 'completion_tokens': 24, 'total_tokens': 357}, 'system_fingerprint': 'fp_68a7d165bf'}, {'remaining-requests': '8', 'remaining-tokens': '9258', 'prompt-tokens': 333, 'completion_tokens': 24, 'total_tokens': 357})\n",
      "(200, {'id': 'chatcmpl-8ngUwhPKkr0blRPF5R0lcT3miLuJd', 'object': 'chat.completion', 'created': 1706852126, 'model': 'gpt-4', 'choices': [{'finish_reason': 'length', 'index': 0, 'message': {'role': 'assistant', 'content': \"You're welcome! If you have any more questions or need further information about Azure services, feel free to ask. Happy\"}}], 'usage': {'prompt_tokens': 333, 'completion_tokens': 24, 'total_tokens': 357}, 'system_fingerprint': 'fp_68a7d165bf'}, {'remaining-requests': '8', 'remaining-tokens': '9258', 'prompt-tokens': 333, 'completion_tokens': 24, 'total_tokens': 357})\n",
      "(200, {'id': 'chatcmpl-8ngUwZzEQ7DKzrmIQDCB5SQVpnz6k', 'object': 'chat.completion', 'created': 1706852126, 'model': 'gpt-4', 'choices': [{'finish_reason': 'length', 'index': 0, 'message': {'role': 'assistant', 'content': \"You're welcome! If you have more questions or need further information about cloud services, Azure, or any other topic,\"}}], 'usage': {'prompt_tokens': 333, 'completion_tokens': 24, 'total_tokens': 357}, 'system_fingerprint': 'fp_68a7d165bf'}, {'remaining-requests': '8', 'remaining-tokens': '9258', 'prompt-tokens': 333, 'completion_tokens': 24, 'total_tokens': 357})\n",
      "(200, {'id': 'chatcmpl-8ngUw2li9k0ZmtfhvYvMC0bAYCpLQ', 'object': 'chat.completion', 'created': 1706852126, 'model': 'gpt-4', 'choices': [{'finish_reason': 'length', 'index': 0, 'message': {'role': 'assistant', 'content': \"You're welcome! If you have any additional questions or need further clarification on any topic, don't hesitate to ask.\"}}], 'usage': {'prompt_tokens': 333, 'completion_tokens': 24, 'total_tokens': 357}, 'system_fingerprint': 'fp_68a7d165bf'}, {'remaining-requests': '7', 'remaining-tokens': '8887', 'prompt-tokens': 333, 'completion_tokens': 24, 'total_tokens': 357})\n",
      "(200, {'id': 'chatcmpl-8ngUwhU60xJpCK0ZcAezyN450rJJM', 'object': 'chat.completion', 'created': 1706852126, 'model': 'gpt-4', 'choices': [{'finish_reason': 'length', 'index': 0, 'message': {'role': 'assistant', 'content': \"You're welcome! I'm here to help. If you have any further questions or need assistance with something else, don\"}}], 'usage': {'prompt_tokens': 333, 'completion_tokens': 24, 'total_tokens': 357}, 'system_fingerprint': 'fp_68a7d165bf'}, {'remaining-requests': '4', 'remaining-tokens': '7774', 'prompt-tokens': 333, 'completion_tokens': 24, 'total_tokens': 357})\n",
      "(200, {'id': 'chatcmpl-8ngUwxzNGpNH9x192HOxhaXOCxkoE', 'object': 'chat.completion', 'created': 1706852126, 'model': 'gpt-4', 'choices': [{'finish_reason': 'length', 'index': 0, 'message': {'role': 'assistant', 'content': \"If you're curious about serverless computing or any other aspect of Azure, don't hesitate to reach out. I'm\"}}], 'usage': {'prompt_tokens': 333, 'completion_tokens': 24, 'total_tokens': 357}, 'system_fingerprint': 'fp_68a7d165bf'}, {'remaining-requests': '4', 'remaining-tokens': '7774', 'prompt-tokens': 333, 'completion_tokens': 24, 'total_tokens': 357})\n",
      "(200, {'id': 'chatcmpl-8ngUwfK8xq7lo5hBh5fkOkhN7fRSJ', 'object': 'chat.completion', 'created': 1706852126, 'model': 'gpt-4', 'choices': [{'finish_reason': 'length', 'index': 0, 'message': {'role': 'assistant', 'content': \"You're welcome! If you have any more questions or need further information about Azure services, cloud computing, or any other\"}}], 'usage': {'prompt_tokens': 333, 'completion_tokens': 24, 'total_tokens': 357}, 'system_fingerprint': 'fp_68a7d165bf'}, {'remaining-requests': '6', 'remaining-tokens': '8516', 'prompt-tokens': 333, 'completion_tokens': 24, 'total_tokens': 357})\n",
      "(200, {'id': 'chatcmpl-8ngUwFt4D1RkwtQeYQyod62nPrMV9', 'object': 'chat.completion', 'created': 1706852126, 'model': 'gpt-4', 'choices': [{'finish_reason': 'length', 'index': 0, 'message': {'role': 'assistant', 'content': \"You're welcome! If you have any more questions or need further clarification on any topic, feel free to reach out.\"}}], 'usage': {'prompt_tokens': 333, 'completion_tokens': 24, 'total_tokens': 357}, 'system_fingerprint': 'fp_68a7d165bf'}, {'remaining-requests': '9', 'remaining-tokens': '9629', 'prompt-tokens': 333, 'completion_tokens': 24, 'total_tokens': 357})\n",
      "(200, {'id': 'chatcmpl-8ngUwwZGIZuJkRBcuaQdYJf1e3ou9', 'object': 'chat.completion', 'created': 1706852126, 'model': 'gpt-4', 'choices': [{'finish_reason': 'length', 'index': 0, 'message': {'role': 'assistant', 'content': 'Absolutely, if you need further assistance, require clarification on a topic, or have more inquiries about Azure services or anything else'}}], 'usage': {'prompt_tokens': 333, 'completion_tokens': 24, 'total_tokens': 357}, 'system_fingerprint': 'fp_68a7d165bf'}, {'remaining-requests': '8', 'remaining-tokens': '9258', 'prompt-tokens': 333, 'completion_tokens': 24, 'total_tokens': 357})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-01 23:35:31,644 - micro - MainProcess - ERROR    HTTP error occurred: 429 Client Error: Too Many Requests for url: https://ml-workspace-dev-canadaeast-001-aoai.openai.azure.com/openai/deployments/foundational-canadaeast-gpt4/chat/completions?api-version=2023-05-15 (2920182161.py:call_azure_openai_chat_completions_api:35)\n",
      "2024-02-01 23:35:31,646 - micro - MainProcess - ERROR    HTTP error occurred: 429 Client Error: Too Many Requests for url: https://ml-workspace-dev-canadaeast-001-aoai.openai.azure.com/openai/deployments/foundational-canadaeast-gpt4/chat/completions?api-version=2023-05-15 (2920182161.py:call_azure_openai_chat_completions_api:35)\n",
      "2024-02-01 23:35:31,653 - micro - MainProcess - ERROR    HTTP error occurred: 429 Client Error: Too Many Requests for url: https://ml-workspace-dev-canadaeast-001-aoai.openai.azure.com/openai/deployments/foundational-canadaeast-gpt4/chat/completions?api-version=2023-05-15 (2920182161.py:call_azure_openai_chat_completions_api:35)\n",
      "2024-02-01 23:35:31,661 - micro - MainProcess - ERROR    HTTP error occurred: 429 Client Error: Too Many Requests for url: https://ml-workspace-dev-canadaeast-001-aoai.openai.azure.com/openai/deployments/foundational-canadaeast-gpt4/chat/completions?api-version=2023-05-15 (2920182161.py:call_azure_openai_chat_completions_api:35)\n",
      "2024-02-01 23:35:31,663 - micro - MainProcess - ERROR    HTTP error occurred: 429 Client Error: Too Many Requests for url: https://ml-workspace-dev-canadaeast-001-aoai.openai.azure.com/openai/deployments/foundational-canadaeast-gpt4/chat/completions?api-version=2023-05-15 (2920182161.py:call_azure_openai_chat_completions_api:35)\n",
      "2024-02-01 23:35:31,692 - micro - MainProcess - ERROR    HTTP error occurred: 429 Client Error: Too Many Requests for url: https://ml-workspace-dev-canadaeast-001-aoai.openai.azure.com/openai/deployments/foundational-canadaeast-gpt4/chat/completions?api-version=2023-05-15 (2920182161.py:call_azure_openai_chat_completions_api:35)\n",
      "2024-02-01 23:35:31,694 - micro - MainProcess - ERROR    HTTP error occurred: 429 Client Error: Too Many Requests for url: https://ml-workspace-dev-canadaeast-001-aoai.openai.azure.com/openai/deployments/foundational-canadaeast-gpt4/chat/completions?api-version=2023-05-15 (2920182161.py:call_azure_openai_chat_completions_api:35)\n",
      "2024-02-01 23:35:31,695 - micro - MainProcess - ERROR    HTTP error occurred: 429 Client Error: Too Many Requests for url: https://ml-workspace-dev-canadaeast-001-aoai.openai.azure.com/openai/deployments/foundational-canadaeast-gpt4/chat/completions?api-version=2023-05-15 (2920182161.py:call_azure_openai_chat_completions_api:35)\n",
      "2024-02-01 23:35:31,705 - micro - MainProcess - ERROR    HTTP error occurred: 429 Client Error: Too Many Requests for url: https://ml-workspace-dev-canadaeast-001-aoai.openai.azure.com/openai/deployments/foundational-canadaeast-gpt4/chat/completions?api-version=2023-05-15 (2920182161.py:call_azure_openai_chat_completions_api:35)\n",
      "2024-02-01 23:35:31,706 - micro - MainProcess - ERROR    HTTP error occurred: 429 Client Error: Too Many Requests for url: https://ml-workspace-dev-canadaeast-001-aoai.openai.azure.com/openai/deployments/foundational-canadaeast-gpt4/chat/completions?api-version=2023-05-15 (2920182161.py:call_azure_openai_chat_completions_api:35)\n",
      "2024-02-01 23:35:34,234 - micro - MainProcess - ERROR    HTTP error occurred: 429 Client Error: Too Many Requests for url: https://ml-workspace-dev-canadaeast-001-aoai.openai.azure.com/openai/deployments/foundational-canadaeast-gpt4/chat/completions?api-version=2023-05-15 (2920182161.py:call_azure_openai_chat_completions_api:35)\n",
      "2024-02-01 23:35:34,290 - micro - MainProcess - ERROR    HTTP error occurred: 429 Client Error: Too Many Requests for url: https://ml-workspace-dev-canadaeast-001-aoai.openai.azure.com/openai/deployments/foundational-canadaeast-gpt4/chat/completions?api-version=2023-05-15 (2920182161.py:call_azure_openai_chat_completions_api:35)\n",
      "2024-02-01 23:35:34,307 - micro - MainProcess - ERROR    HTTP error occurred: 429 Client Error: Too Many Requests for url: https://ml-workspace-dev-canadaeast-001-aoai.openai.azure.com/openai/deployments/foundational-canadaeast-gpt4/chat/completions?api-version=2023-05-15 (2920182161.py:call_azure_openai_chat_completions_api:35)\n",
      "2024-02-01 23:35:34,310 - micro - MainProcess - ERROR    HTTP error occurred: 429 Client Error: Too Many Requests for url: https://ml-workspace-dev-canadaeast-001-aoai.openai.azure.com/openai/deployments/foundational-canadaeast-gpt4/chat/completions?api-version=2023-05-15 (2920182161.py:call_azure_openai_chat_completions_api:35)\n",
      "2024-02-01 23:35:34,316 - micro - MainProcess - ERROR    HTTP error occurred: 429 Client Error: Too Many Requests for url: https://ml-workspace-dev-canadaeast-001-aoai.openai.azure.com/openai/deployments/foundational-canadaeast-gpt4/chat/completions?api-version=2023-05-15 (2920182161.py:call_azure_openai_chat_completions_api:35)\n",
      "2024-02-01 23:35:34,385 - micro - MainProcess - ERROR    HTTP error occurred: 429 Client Error: Too Many Requests for url: https://ml-workspace-dev-canadaeast-001-aoai.openai.azure.com/openai/deployments/foundational-canadaeast-gpt4/chat/completions?api-version=2023-05-15 (2920182161.py:call_azure_openai_chat_completions_api:35)\n",
      "2024-02-01 23:35:34,389 - micro - MainProcess - ERROR    HTTP error occurred: 429 Client Error: Too Many Requests for url: https://ml-workspace-dev-canadaeast-001-aoai.openai.azure.com/openai/deployments/foundational-canadaeast-gpt4/chat/completions?api-version=2023-05-15 (2920182161.py:call_azure_openai_chat_completions_api:35)\n",
      "2024-02-01 23:35:34,394 - micro - MainProcess - ERROR    HTTP error occurred: 429 Client Error: Too Many Requests for url: https://ml-workspace-dev-canadaeast-001-aoai.openai.azure.com/openai/deployments/foundational-canadaeast-gpt4/chat/completions?api-version=2023-05-15 (2920182161.py:call_azure_openai_chat_completions_api:35)\n",
      "2024-02-01 23:35:34,395 - micro - MainProcess - ERROR    HTTP error occurred: 429 Client Error: Too Many Requests for url: https://ml-workspace-dev-canadaeast-001-aoai.openai.azure.com/openai/deployments/foundational-canadaeast-gpt4/chat/completions?api-version=2023-05-15 (2920182161.py:call_azure_openai_chat_completions_api:35)\n",
      "2024-02-01 23:35:34,401 - micro - MainProcess - ERROR    HTTP error occurred: 429 Client Error: Too Many Requests for url: https://ml-workspace-dev-canadaeast-001-aoai.openai.azure.com/openai/deployments/foundational-canadaeast-gpt4/chat/completions?api-version=2023-05-15 (2920182161.py:call_azure_openai_chat_completions_api:35)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(429, {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-05-15 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}, {})\n",
      "(429, {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-05-15 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}, {})\n",
      "(429, {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-05-15 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}, {})\n",
      "(429, {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-05-15 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}, {})\n",
      "(429, {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-05-15 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}, {})\n",
      "(429, {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-05-15 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}, {})\n",
      "(429, {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-05-15 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}, {})\n",
      "(429, {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-05-15 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}, {})\n",
      "(429, {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-05-15 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}, {})\n",
      "(429, {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-05-15 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}, {})\n",
      "{'Cache-Control': 'no-cache, must-revalidate', 'Content-Length': '420', 'Content-Type': 'application/json', 'access-control-allow-origin': '*', 'apim-request-id': '611d6b4f-fa02-4ded-a4f5-19c68a8d10fe', 'Strict-Transport-Security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'x-ms-region': 'Canada East', 'x-ratelimit-remaining-requests': '6', 'x-ratelimit-remaining-tokens': '4806', 'x-accel-buffering': 'no', 'x-request-id': 'a021b82e-2404-460a-a65c-a2eb287d3eb5', 'x-ms-client-request-id': '611d6b4f-fa02-4ded-a4f5-19c68a8d10fe', 'azureml-model-session': 'd018-20240201032837', 'Date': 'Fri, 02 Feb 2024 05:35:38 GMT'}\n",
      "{'Cache-Control': 'no-cache, must-revalidate', 'Content-Length': '425', 'Content-Type': 'application/json', 'access-control-allow-origin': '*', 'apim-request-id': '7daa47e3-fb25-4170-a3b7-f9d17b9a88ef', 'Strict-Transport-Security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'x-ms-region': 'Canada East', 'x-ratelimit-remaining-requests': '8', 'x-ratelimit-remaining-tokens': '5548', 'x-accel-buffering': 'no', 'x-request-id': '1441636c-ed53-4a9d-becc-2f021ae5dd3e', 'x-ms-client-request-id': '7daa47e3-fb25-4170-a3b7-f9d17b9a88ef', 'azureml-model-session': 'd018-20240201032837', 'Date': 'Fri, 02 Feb 2024 05:35:38 GMT'}\n",
      "{'Cache-Control': 'no-cache, must-revalidate', 'Content-Length': '378', 'Content-Type': 'application/json', 'access-control-allow-origin': '*', 'apim-request-id': 'de43dd0b-cc38-4f43-9211-82e3162160e7', 'Strict-Transport-Security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'x-ms-region': 'Canada East', 'x-ratelimit-remaining-requests': '8', 'x-ratelimit-remaining-tokens': '5548', 'x-accel-buffering': 'no', 'x-request-id': 'd12bc1c9-83b5-4b8d-a256-9ea5029357ff', 'x-ms-client-request-id': 'de43dd0b-cc38-4f43-9211-82e3162160e7', 'azureml-model-session': 'd018-20240201032837', 'Date': 'Fri, 02 Feb 2024 05:35:39 GMT'}\n",
      "{'Cache-Control': 'no-cache, must-revalidate', 'Content-Length': '431', 'Content-Type': 'application/json', 'access-control-allow-origin': '*', 'apim-request-id': '0749aec6-7c53-460d-bbcd-f661d844128f', 'Strict-Transport-Security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'x-ms-region': 'Canada East', 'x-ratelimit-remaining-requests': '9', 'x-ratelimit-remaining-tokens': '5919', 'x-accel-buffering': 'no', 'x-request-id': 'c5330476-29e2-4dce-8fde-10fbddd12619', 'x-ms-client-request-id': '0749aec6-7c53-460d-bbcd-f661d844128f', 'azureml-model-session': 'd023-20240201080125', 'Date': 'Fri, 02 Feb 2024 05:35:39 GMT'}\n",
      "{'Cache-Control': 'no-cache, must-revalidate', 'Content-Length': '424', 'Content-Type': 'application/json', 'access-control-allow-origin': '*', 'apim-request-id': '68b254f1-e1db-42ba-92b4-fea43150b32c', 'Strict-Transport-Security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'x-ms-region': 'Canada East', 'x-ratelimit-remaining-requests': '9', 'x-ratelimit-remaining-tokens': '5919', 'x-accel-buffering': 'no', 'x-request-id': 'e3ad9469-a597-497a-b0bb-c4e02b47048c', 'x-ms-client-request-id': '68b254f1-e1db-42ba-92b4-fea43150b32c', 'azureml-model-session': 'd023-20240201080125', 'Date': 'Fri, 02 Feb 2024 05:35:38 GMT'}\n",
      "{'Cache-Control': 'no-cache, must-revalidate', 'Content-Length': '421', 'Content-Type': 'application/json', 'access-control-allow-origin': '*', 'apim-request-id': '0163439d-4b7d-4950-b861-7663498a5f8e', 'Strict-Transport-Security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'x-ms-region': 'Canada East', 'x-ratelimit-remaining-requests': '6', 'x-ratelimit-remaining-tokens': '4806', 'x-accel-buffering': 'no', 'x-request-id': 'e413844c-741c-41e8-b66c-678fd8876da0', 'x-ms-client-request-id': '0163439d-4b7d-4950-b861-7663498a5f8e', 'azureml-model-session': 'd023-20240201080125', 'Date': 'Fri, 02 Feb 2024 05:35:39 GMT'}\n",
      "{'Cache-Control': 'no-cache, must-revalidate', 'Content-Length': '427', 'Content-Type': 'application/json', 'access-control-allow-origin': '*', 'apim-request-id': '14681d2e-9a40-40d5-b053-55de0d1900d0', 'Strict-Transport-Security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'x-ms-region': 'Canada East', 'x-ratelimit-remaining-requests': '5', 'x-ratelimit-remaining-tokens': '4435', 'x-accel-buffering': 'no', 'x-request-id': '1194f4ee-3735-4a24-a784-21655c3989df', 'x-ms-client-request-id': '14681d2e-9a40-40d5-b053-55de0d1900d0', 'azureml-model-session': 'd023-20240201080125', 'Date': 'Fri, 02 Feb 2024 05:35:39 GMT'}\n",
      "{'Cache-Control': 'no-cache, must-revalidate', 'Content-Length': '432', 'Content-Type': 'application/json', 'access-control-allow-origin': '*', 'apim-request-id': '9fe6bf3c-a67c-484f-977f-de5b26889dc0', 'Strict-Transport-Security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'x-ms-region': 'Canada East', 'x-ratelimit-remaining-requests': '5', 'x-ratelimit-remaining-tokens': '4435', 'x-accel-buffering': 'no', 'x-request-id': '4fde77ff-38fc-433b-b1f6-a5e1885390da', 'x-ms-client-request-id': '9fe6bf3c-a67c-484f-977f-de5b26889dc0', 'azureml-model-session': 'd017-20240201023444', 'Date': 'Fri, 02 Feb 2024 05:35:39 GMT'}\n",
      "{'Cache-Control': 'no-cache, must-revalidate', 'Content-Length': '426', 'Content-Type': 'application/json', 'access-control-allow-origin': '*', 'apim-request-id': 'd96b8b24-3a91-4f0a-8922-30cb49444023', 'Strict-Transport-Security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'x-ms-region': 'Canada East', 'x-ratelimit-remaining-requests': '7', 'x-ratelimit-remaining-tokens': '5177', 'x-accel-buffering': 'no', 'x-request-id': 'a0065a87-32fa-40b6-bea6-1fcf077ad424', 'x-ms-client-request-id': 'd96b8b24-3a91-4f0a-8922-30cb49444023', 'azureml-model-session': 'd017-20240201023444', 'Date': 'Fri, 02 Feb 2024 05:35:40 GMT'}\n",
      "{'Cache-Control': 'no-cache, must-revalidate', 'Content-Length': '426', 'Content-Type': 'application/json', 'access-control-allow-origin': '*', 'apim-request-id': '54878bee-6dad-4f30-90d3-2f3658de44d4', 'Strict-Transport-Security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'x-ms-region': 'Canada East', 'x-ratelimit-remaining-requests': '5', 'x-ratelimit-remaining-tokens': '4435', 'x-accel-buffering': 'no', 'x-request-id': '284af578-ce6c-4ff6-aa97-5cb1819c259a', 'x-ms-client-request-id': '54878bee-6dad-4f30-90d3-2f3658de44d4', 'azureml-model-session': 'd017-20240201023444', 'Date': 'Fri, 02 Feb 2024 05:35:40 GMT'}\n",
      "(200, {'id': 'chatcmpl-8ngV8zpOiYm9Gha3kedqKUYO09XPK', 'object': 'chat.completion', 'created': 1706852138, 'model': 'gpt-4', 'choices': [{'finish_reason': 'length', 'index': 0, 'message': {'role': 'assistant', 'content': \"You're welcome! If you have any more questions or need further clarification on any topic, feel free to ask. I\"}}], 'usage': {'prompt_tokens': 333, 'completion_tokens': 24, 'total_tokens': 357}, 'system_fingerprint': 'fp_68a7d165bf'}, {'remaining-requests': '9', 'remaining-tokens': '5919', 'prompt-tokens': 333, 'completion_tokens': 24, 'total_tokens': 357})\n",
      "(200, {'id': 'chatcmpl-8ngV8Rvwt5EPgrRPQqs0bPECy7cqQ', 'object': 'chat.completion', 'created': 1706852138, 'model': 'gpt-4', 'choices': [{'finish_reason': 'length', 'index': 0, 'message': {'role': 'assistant', 'content': \"You're welcome! If you have any further questions or need assistance with anything else, don't hesitate to ask. Happy\"}}], 'usage': {'prompt_tokens': 333, 'completion_tokens': 24, 'total_tokens': 357}, 'system_fingerprint': 'fp_68a7d165bf'}, {'remaining-requests': '9', 'remaining-tokens': '5919', 'prompt-tokens': 333, 'completion_tokens': 24, 'total_tokens': 357})\n",
      "(200, {'id': 'chatcmpl-8ngV8zIpVIFDBZuwVWn7uL4ChPswg', 'object': 'chat.completion', 'created': 1706852138, 'model': 'gpt-4', 'choices': [{'finish_reason': 'length', 'index': 0, 'message': {'role': 'assistant', 'content': \"You're welcome! If you have any more questions or need further clarification on anything, feel free to ask. I'm\"}}], 'usage': {'prompt_tokens': 333, 'completion_tokens': 24, 'total_tokens': 357}, 'system_fingerprint': 'fp_68a7d165bf'}, {'remaining-requests': '8', 'remaining-tokens': '5548', 'prompt-tokens': 333, 'completion_tokens': 24, 'total_tokens': 357})\n",
      "(200, {'id': 'chatcmpl-8ngV8fQyKcq5oIfDlxy8hiZAtngHE', 'object': 'chat.completion', 'created': 1706852138, 'model': 'gpt-4', 'choices': [{'finish_reason': 'length', 'index': 0, 'message': {'role': 'assistant', 'content': \"You're welcome! If you have any more questions or need further information, don't hesitate to ask. I'm here\"}}], 'usage': {'prompt_tokens': 333, 'completion_tokens': 24, 'total_tokens': 357}, 'system_fingerprint': 'fp_68a7d165bf'}, {'remaining-requests': '6', 'remaining-tokens': '4806', 'prompt-tokens': 333, 'completion_tokens': 24, 'total_tokens': 357})\n",
      "(200, {'id': 'chatcmpl-8ngV8zSRNOAfPfVOnhT8GAdXwJCY2', 'object': 'chat.completion', 'created': 1706852138, 'model': 'gpt-4', 'choices': [{'finish_reason': 'length', 'index': 0, 'message': {'role': 'assistant', 'content': \"You're welcome! If you have any more questions or need further assistance, don't hesitate to reach out. Happy to\"}}], 'usage': {'prompt_tokens': 333, 'completion_tokens': 24, 'total_tokens': 357}, 'system_fingerprint': 'fp_68a7d165bf'}, {'remaining-requests': '5', 'remaining-tokens': '4435', 'prompt-tokens': 333, 'completion_tokens': 24, 'total_tokens': 357})\n",
      "(200, {'id': 'chatcmpl-8ngV8w2GtzNy1LwlFR2UUk2YSORLa', 'object': 'chat.completion', 'created': 1706852138, 'model': 'gpt-4', 'choices': [{'finish_reason': 'length', 'index': 0, 'message': {'role': 'assistant', 'content': \"You're welcome! If there's anything else you want to know or if you have further questions on Azure or any other\"}}], 'usage': {'prompt_tokens': 333, 'completion_tokens': 24, 'total_tokens': 357}, 'system_fingerprint': 'fp_68a7d165bf'}, {'remaining-requests': '7', 'remaining-tokens': '5177', 'prompt-tokens': 333, 'completion_tokens': 24, 'total_tokens': 357})\n",
      "(200, {'id': 'chatcmpl-8ngV8xo126hgHeZEHnO9mslYBvRBg', 'object': 'chat.completion', 'created': 1706852138, 'model': 'gpt-4', 'choices': [{'finish_reason': 'length', 'index': 0, 'message': {'role': 'assistant', 'content': \"You're welcome! If you have any more questions on Azure, Cloud Computing, or any other topic, feel free to\"}}], 'usage': {'prompt_tokens': 333, 'completion_tokens': 24, 'total_tokens': 357}, 'system_fingerprint': 'fp_68a7d165bf'}, {'remaining-requests': '6', 'remaining-tokens': '4806', 'prompt-tokens': 333, 'completion_tokens': 24, 'total_tokens': 357})\n",
      "(200, {'id': 'chatcmpl-8ngV89yXswKrCVbOGF4lz3Fzj90eq', 'object': 'chat.completion', 'created': 1706852138, 'model': 'gpt-4', 'choices': [{'finish_reason': 'length', 'index': 0, 'message': {'role': 'assistant', 'content': \"If you have any further questions or need assistance with anything else, don't hesitate to reach out. Have a great day\"}}], 'usage': {'prompt_tokens': 333, 'completion_tokens': 24, 'total_tokens': 357}, 'system_fingerprint': 'fp_68a7d165bf'}, {'remaining-requests': '5', 'remaining-tokens': '4435', 'prompt-tokens': 333, 'completion_tokens': 24, 'total_tokens': 357})\n",
      "(200, {'id': 'chatcmpl-8ngV8LxJTMAAfgr89KUjdZJqFYAHH', 'object': 'chat.completion', 'created': 1706852138, 'model': 'gpt-4', 'choices': [{'finish_reason': 'length', 'index': 0, 'message': {'role': 'assistant', 'content': \"You're welcome! If you have any further questions or need assistance with anything else, don't hesitate to ask. I\"}}], 'usage': {'prompt_tokens': 333, 'completion_tokens': 24, 'total_tokens': 357}, 'system_fingerprint': 'fp_68a7d165bf'}, {'remaining-requests': '5', 'remaining-tokens': '4435', 'prompt-tokens': 333, 'completion_tokens': 24, 'total_tokens': 357})\n",
      "(200, {'id': 'chatcmpl-8ngV8MWH3M522Jc759CTxR3N1CdqL', 'object': 'chat.completion', 'created': 1706852138, 'model': 'gpt-4', 'choices': [{'finish_reason': 'stop', 'index': 0, 'message': {'role': 'assistant', 'content': \"You're welcome! If you have any other questions, feel free to ask.\"}}], 'usage': {'prompt_tokens': 333, 'completion_tokens': 16, 'total_tokens': 349}, 'system_fingerprint': 'fp_68a7d165bf'}, {'remaining-requests': '8', 'remaining-tokens': '5548', 'prompt-tokens': 333, 'completion_tokens': 16, 'total_tokens': 349})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-01 23:35:43,553 - micro - MainProcess - ERROR    HTTP error occurred: 429 Client Error: Too Many Requests for url: https://ml-workspace-dev-canadaeast-001-aoai.openai.azure.com/openai/deployments/foundational-canadaeast-gpt4/chat/completions?api-version=2023-05-15 (2920182161.py:call_azure_openai_chat_completions_api:35)\n",
      "2024-02-01 23:35:43,562 - micro - MainProcess - ERROR    HTTP error occurred: 429 Client Error: Too Many Requests for url: https://ml-workspace-dev-canadaeast-001-aoai.openai.azure.com/openai/deployments/foundational-canadaeast-gpt4/chat/completions?api-version=2023-05-15 (2920182161.py:call_azure_openai_chat_completions_api:35)\n",
      "2024-02-01 23:35:43,565 - micro - MainProcess - ERROR    HTTP error occurred: 429 Client Error: Too Many Requests for url: https://ml-workspace-dev-canadaeast-001-aoai.openai.azure.com/openai/deployments/foundational-canadaeast-gpt4/chat/completions?api-version=2023-05-15 (2920182161.py:call_azure_openai_chat_completions_api:35)\n",
      "2024-02-01 23:35:43,578 - micro - MainProcess - ERROR    HTTP error occurred: 429 Client Error: Too Many Requests for url: https://ml-workspace-dev-canadaeast-001-aoai.openai.azure.com/openai/deployments/foundational-canadaeast-gpt4/chat/completions?api-version=2023-05-15 (2920182161.py:call_azure_openai_chat_completions_api:35)\n",
      "2024-02-01 23:35:43,582 - micro - MainProcess - ERROR    HTTP error occurred: 429 Client Error: Too Many Requests for url: https://ml-workspace-dev-canadaeast-001-aoai.openai.azure.com/openai/deployments/foundational-canadaeast-gpt4/chat/completions?api-version=2023-05-15 (2920182161.py:call_azure_openai_chat_completions_api:35)\n",
      "2024-02-01 23:35:43,588 - micro - MainProcess - ERROR    HTTP error occurred: 429 Client Error: Too Many Requests for url: https://ml-workspace-dev-canadaeast-001-aoai.openai.azure.com/openai/deployments/foundational-canadaeast-gpt4/chat/completions?api-version=2023-05-15 (2920182161.py:call_azure_openai_chat_completions_api:35)\n",
      "2024-02-01 23:35:43,598 - micro - MainProcess - ERROR    HTTP error occurred: 429 Client Error: Too Many Requests for url: https://ml-workspace-dev-canadaeast-001-aoai.openai.azure.com/openai/deployments/foundational-canadaeast-gpt4/chat/completions?api-version=2023-05-15 (2920182161.py:call_azure_openai_chat_completions_api:35)\n",
      "2024-02-01 23:35:43,602 - micro - MainProcess - ERROR    HTTP error occurred: 429 Client Error: Too Many Requests for url: https://ml-workspace-dev-canadaeast-001-aoai.openai.azure.com/openai/deployments/foundational-canadaeast-gpt4/chat/completions?api-version=2023-05-15 (2920182161.py:call_azure_openai_chat_completions_api:35)\n",
      "2024-02-01 23:35:43,609 - micro - MainProcess - ERROR    HTTP error occurred: 429 Client Error: Too Many Requests for url: https://ml-workspace-dev-canadaeast-001-aoai.openai.azure.com/openai/deployments/foundational-canadaeast-gpt4/chat/completions?api-version=2023-05-15 (2920182161.py:call_azure_openai_chat_completions_api:35)\n",
      "2024-02-01 23:35:43,621 - micro - MainProcess - ERROR    HTTP error occurred: 429 Client Error: Too Many Requests for url: https://ml-workspace-dev-canadaeast-001-aoai.openai.azure.com/openai/deployments/foundational-canadaeast-gpt4/chat/completions?api-version=2023-05-15 (2920182161.py:call_azure_openai_chat_completions_api:35)\n",
      "2024-02-01 23:35:46,064 - micro - MainProcess - ERROR    HTTP error occurred: 429 Client Error: Too Many Requests for url: https://ml-workspace-dev-canadaeast-001-aoai.openai.azure.com/openai/deployments/foundational-canadaeast-gpt4/chat/completions?api-version=2023-05-15 (2920182161.py:call_azure_openai_chat_completions_api:35)\n",
      "2024-02-01 23:35:46,114 - micro - MainProcess - ERROR    HTTP error occurred: 429 Client Error: Too Many Requests for url: https://ml-workspace-dev-canadaeast-001-aoai.openai.azure.com/openai/deployments/foundational-canadaeast-gpt4/chat/completions?api-version=2023-05-15 (2920182161.py:call_azure_openai_chat_completions_api:35)\n",
      "2024-02-01 23:35:46,135 - micro - MainProcess - ERROR    HTTP error occurred: 429 Client Error: Too Many Requests for url: https://ml-workspace-dev-canadaeast-001-aoai.openai.azure.com/openai/deployments/foundational-canadaeast-gpt4/chat/completions?api-version=2023-05-15 (2920182161.py:call_azure_openai_chat_completions_api:35)\n",
      "2024-02-01 23:35:46,179 - micro - MainProcess - ERROR    HTTP error occurred: 429 Client Error: Too Many Requests for url: https://ml-workspace-dev-canadaeast-001-aoai.openai.azure.com/openai/deployments/foundational-canadaeast-gpt4/chat/completions?api-version=2023-05-15 (2920182161.py:call_azure_openai_chat_completions_api:35)\n",
      "2024-02-01 23:35:46,195 - micro - MainProcess - ERROR    HTTP error occurred: 429 Client Error: Too Many Requests for url: https://ml-workspace-dev-canadaeast-001-aoai.openai.azure.com/openai/deployments/foundational-canadaeast-gpt4/chat/completions?api-version=2023-05-15 (2920182161.py:call_azure_openai_chat_completions_api:35)\n",
      "2024-02-01 23:35:46,218 - micro - MainProcess - ERROR    HTTP error occurred: 429 Client Error: Too Many Requests for url: https://ml-workspace-dev-canadaeast-001-aoai.openai.azure.com/openai/deployments/foundational-canadaeast-gpt4/chat/completions?api-version=2023-05-15 (2920182161.py:call_azure_openai_chat_completions_api:35)\n",
      "2024-02-01 23:35:46,218 - micro - MainProcess - ERROR    HTTP error occurred: 429 Client Error: Too Many Requests for url: https://ml-workspace-dev-canadaeast-001-aoai.openai.azure.com/openai/deployments/foundational-canadaeast-gpt4/chat/completions?api-version=2023-05-15 (2920182161.py:call_azure_openai_chat_completions_api:35)\n",
      "2024-02-01 23:35:46,244 - micro - MainProcess - ERROR    HTTP error occurred: 429 Client Error: Too Many Requests for url: https://ml-workspace-dev-canadaeast-001-aoai.openai.azure.com/openai/deployments/foundational-canadaeast-gpt4/chat/completions?api-version=2023-05-15 (2920182161.py:call_azure_openai_chat_completions_api:35)\n",
      "2024-02-01 23:35:46,249 - micro - MainProcess - ERROR    HTTP error occurred: 429 Client Error: Too Many Requests for url: https://ml-workspace-dev-canadaeast-001-aoai.openai.azure.com/openai/deployments/foundational-canadaeast-gpt4/chat/completions?api-version=2023-05-15 (2920182161.py:call_azure_openai_chat_completions_api:35)\n",
      "2024-02-01 23:35:46,253 - micro - MainProcess - ERROR    HTTP error occurred: 429 Client Error: Too Many Requests for url: https://ml-workspace-dev-canadaeast-001-aoai.openai.azure.com/openai/deployments/foundational-canadaeast-gpt4/chat/completions?api-version=2023-05-15 (2920182161.py:call_azure_openai_chat_completions_api:35)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(429, {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-05-15 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}, {})\n",
      "(429, {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-05-15 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}, {})\n",
      "(429, {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-05-15 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}, {})\n",
      "(429, {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-05-15 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}, {})\n",
      "(429, {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-05-15 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}, {})\n",
      "(429, {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-05-15 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}, {})\n",
      "(429, {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-05-15 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}, {})\n",
      "(429, {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-05-15 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}, {})\n",
      "(429, {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-05-15 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}, {})\n",
      "(429, {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-05-15 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}, {})\n",
      "{'Cache-Control': 'no-cache, must-revalidate', 'Content-Length': '378', 'Content-Type': 'application/json', 'access-control-allow-origin': '*', 'apim-request-id': '357c9936-8f8a-4e3a-bda7-11ddd31248ec', 'Strict-Transport-Security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'x-ms-region': 'Canada East', 'x-ratelimit-remaining-requests': '9', 'x-ratelimit-remaining-tokens': '2209', 'x-accel-buffering': 'no', 'x-request-id': 'd02b6e12-f0f1-4bb5-af2f-53449936f45f', 'x-ms-client-request-id': '357c9936-8f8a-4e3a-bda7-11ddd31248ec', 'azureml-model-session': 'd023-20240201080125', 'Date': 'Fri, 02 Feb 2024 05:35:50 GMT'}\n",
      "{'Cache-Control': 'no-cache, must-revalidate', 'Content-Length': '378', 'Content-Type': 'application/json', 'access-control-allow-origin': '*', 'apim-request-id': 'dfb48fb1-d280-4ede-9989-879f074da795', 'Strict-Transport-Security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'x-ms-region': 'Canada East', 'x-ratelimit-remaining-requests': '7', 'x-ratelimit-remaining-tokens': '1467', 'x-accel-buffering': 'no', 'x-request-id': 'ef9bb6a9-fb99-49b4-9756-d277aafeccf1', 'x-ms-client-request-id': 'dfb48fb1-d280-4ede-9989-879f074da795', 'azureml-model-session': 'd023-20240201080125', 'Date': 'Fri, 02 Feb 2024 05:35:50 GMT'}\n",
      "{'Cache-Control': 'no-cache, must-revalidate', 'Content-Length': '426', 'Content-Type': 'application/json', 'access-control-allow-origin': '*', 'apim-request-id': '391bd2c5-92e6-489c-9073-13d166ffef36', 'Strict-Transport-Security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'x-ms-region': 'Canada East', 'x-ratelimit-remaining-requests': '7', 'x-ratelimit-remaining-tokens': '1467', 'x-accel-buffering': 'no', 'x-request-id': '98df83f3-196b-4f9f-89dc-46ca5c086488', 'x-ms-client-request-id': '391bd2c5-92e6-489c-9073-13d166ffef36', 'azureml-model-session': 'd016-20240201014049', 'Date': 'Fri, 02 Feb 2024 05:35:50 GMT'}\n",
      "{'Cache-Control': 'no-cache, must-revalidate', 'Content-Length': '425', 'Content-Type': 'application/json', 'access-control-allow-origin': '*', 'apim-request-id': '8324cb36-6cd4-4c38-8dcd-e2342ea1bd5a', 'Strict-Transport-Security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'x-ms-region': 'Canada East', 'x-ratelimit-remaining-requests': '9', 'x-ratelimit-remaining-tokens': '2209', 'x-accel-buffering': 'no', 'x-request-id': 'c05b8551-110c-4d91-9bc4-b2d1af279edc', 'x-ms-client-request-id': '8324cb36-6cd4-4c38-8dcd-e2342ea1bd5a', 'azureml-model-session': 'd018-20240201032837', 'Date': 'Fri, 02 Feb 2024 05:35:50 GMT'}\n",
      "{'Cache-Control': 'no-cache, must-revalidate', 'Content-Length': '429', 'Content-Type': 'application/json', 'access-control-allow-origin': '*', 'apim-request-id': 'fabdecb6-df54-42dc-b722-f0e95c706e54', 'Strict-Transport-Security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'x-ms-region': 'Canada East', 'x-ratelimit-remaining-requests': '7', 'x-ratelimit-remaining-tokens': '1467', 'x-accel-buffering': 'no', 'x-request-id': '05a869b5-1900-40c0-aed0-49a3422f6b67', 'x-ms-client-request-id': 'fabdecb6-df54-42dc-b722-f0e95c706e54', 'azureml-model-session': 'd017-20240201023444', 'Date': 'Fri, 02 Feb 2024 05:35:50 GMT'}\n",
      "{'Cache-Control': 'no-cache, must-revalidate', 'Content-Length': '417', 'Content-Type': 'application/json', 'access-control-allow-origin': '*', 'apim-request-id': 'cb3beeed-8923-4b1e-a6ac-1e470a809948', 'Strict-Transport-Security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'x-ms-region': 'Canada East', 'x-ratelimit-remaining-requests': '7', 'x-ratelimit-remaining-tokens': '1467', 'x-accel-buffering': 'no', 'x-request-id': 'fb7e41a3-29b1-4a27-8698-9bfed5ad1cd9', 'x-ms-client-request-id': 'cb3beeed-8923-4b1e-a6ac-1e470a809948', 'azureml-model-session': 'd018-20240201032837', 'Date': 'Fri, 02 Feb 2024 05:35:51 GMT'}\n",
      "{'Cache-Control': 'no-cache, must-revalidate', 'Content-Length': '427', 'Content-Type': 'application/json', 'access-control-allow-origin': '*', 'apim-request-id': 'b02c758e-e217-4872-af81-0319453c2943', 'Strict-Transport-Security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'x-ms-region': 'Canada East', 'x-ratelimit-remaining-requests': '7', 'x-ratelimit-remaining-tokens': '1467', 'x-accel-buffering': 'no', 'x-request-id': 'f12b8832-60d1-4746-8acc-dcacf72a7b8b', 'x-ms-client-request-id': 'b02c758e-e217-4872-af81-0319453c2943', 'azureml-model-session': 'd018-20240201032837', 'Date': 'Fri, 02 Feb 2024 05:35:50 GMT'}\n",
      "{'Cache-Control': 'no-cache, must-revalidate', 'Content-Length': '421', 'Content-Type': 'application/json', 'access-control-allow-origin': '*', 'apim-request-id': '6c70a452-153e-449c-aa40-9b714e849b50', 'Strict-Transport-Security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'x-ms-region': 'Canada East', 'x-ratelimit-remaining-requests': '5', 'x-ratelimit-remaining-tokens': '725', 'x-accel-buffering': 'no', 'x-request-id': '41f0fc0c-36a8-4983-ada5-19ed32a45a15', 'x-ms-client-request-id': '6c70a452-153e-449c-aa40-9b714e849b50', 'azureml-model-session': 'd023-20240201080125', 'Date': 'Fri, 02 Feb 2024 05:35:51 GMT'}\n",
      "{'Cache-Control': 'no-cache, must-revalidate', 'Content-Length': '422', 'Content-Type': 'application/json', 'access-control-allow-origin': '*', 'apim-request-id': 'e63a93c3-acdf-4726-92f1-f2749d338d1f', 'Strict-Transport-Security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'x-ms-region': 'Canada East', 'x-ratelimit-remaining-requests': '8', 'x-ratelimit-remaining-tokens': '1838', 'x-accel-buffering': 'no', 'x-request-id': '57de90dd-ec30-4f6e-aabe-4d5f2ed27a8d', 'x-ms-client-request-id': 'e63a93c3-acdf-4726-92f1-f2749d338d1f', 'azureml-model-session': 'd023-20240201080125', 'Date': 'Fri, 02 Feb 2024 05:35:51 GMT'}\n",
      "{'Cache-Control': 'no-cache, must-revalidate', 'Content-Length': '428', 'Content-Type': 'application/json', 'access-control-allow-origin': '*', 'apim-request-id': '53793da4-4d39-40ed-a09e-db31d8f15714', 'Strict-Transport-Security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'x-ms-region': 'Canada East', 'x-ratelimit-remaining-requests': '7', 'x-ratelimit-remaining-tokens': '1467', 'x-accel-buffering': 'no', 'x-request-id': '942c2c12-edc5-46b8-9043-c5a6fb68dac8', 'x-ms-client-request-id': '53793da4-4d39-40ed-a09e-db31d8f15714', 'azureml-model-session': 'd016-20240201014049', 'Date': 'Fri, 02 Feb 2024 05:35:51 GMT'}\n",
      "(200, {'id': 'chatcmpl-8ngVK2lyS65keZT06zyUEieSalIys', 'object': 'chat.completion', 'created': 1706852150, 'model': 'gpt-4', 'choices': [{'finish_reason': 'length', 'index': 0, 'message': {'role': 'assistant', 'content': \"You're very welcome! If you have further questions or need assistance with anything else, feel free to reach out. I\"}}], 'usage': {'prompt_tokens': 333, 'completion_tokens': 24, 'total_tokens': 357}, 'system_fingerprint': 'fp_68a7d165bf'}, {'remaining-requests': '7', 'remaining-tokens': '1467', 'prompt-tokens': 333, 'completion_tokens': 24, 'total_tokens': 357})\n",
      "(200, {'id': 'chatcmpl-8ngVKnXxM5jJPE9kACUuTklP1DTY1', 'object': 'chat.completion', 'created': 1706852150, 'model': 'gpt-4', 'choices': [{'finish_reason': 'length', 'index': 0, 'message': {'role': 'assistant', 'content': \"You're welcome! If you have any further questions or need assistance with anything else, don't hesitate to ask. I\"}}], 'usage': {'prompt_tokens': 333, 'completion_tokens': 24, 'total_tokens': 357}, 'system_fingerprint': 'fp_68a7d165bf'}, {'remaining-requests': '7', 'remaining-tokens': '1467', 'prompt-tokens': 333, 'completion_tokens': 24, 'total_tokens': 357})\n",
      "(200, {'id': 'chatcmpl-8ngVK60dgVV6mSfbpTDZfESEWX1JU', 'object': 'chat.completion', 'created': 1706852150, 'model': 'gpt-4', 'choices': [{'finish_reason': 'length', 'index': 0, 'message': {'role': 'assistant', 'content': \"You're welcome! If you have any more questions or need further assistance, feel free to reach out. Happy to help\"}}], 'usage': {'prompt_tokens': 333, 'completion_tokens': 24, 'total_tokens': 357}, 'system_fingerprint': 'fp_68a7d165bf'}, {'remaining-requests': '7', 'remaining-tokens': '1467', 'prompt-tokens': 333, 'completion_tokens': 24, 'total_tokens': 357})\n",
      "(200, {'id': 'chatcmpl-8ngVKCQd8kWYF09TufZN4kxLFMMXf', 'object': 'chat.completion', 'created': 1706852150, 'model': 'gpt-4', 'choices': [{'finish_reason': 'stop', 'index': 0, 'message': {'role': 'assistant', 'content': \"You're welcome! If you have any other questions, feel free to ask.\"}}], 'usage': {'prompt_tokens': 333, 'completion_tokens': 16, 'total_tokens': 349}, 'system_fingerprint': 'fp_68a7d165bf'}, {'remaining-requests': '7', 'remaining-tokens': '1467', 'prompt-tokens': 333, 'completion_tokens': 16, 'total_tokens': 349})\n",
      "(200, {'id': 'chatcmpl-8ngVJJurg9XlQAyWN88GSegDk4WcH', 'object': 'chat.completion', 'created': 1706852149, 'model': 'gpt-4', 'choices': [{'finish_reason': 'stop', 'index': 0, 'message': {'role': 'assistant', 'content': \"You're welcome! If you have any other questions, feel free to ask.\"}}], 'usage': {'prompt_tokens': 333, 'completion_tokens': 16, 'total_tokens': 349}, 'system_fingerprint': 'fp_68a7d165bf'}, {'remaining-requests': '9', 'remaining-tokens': '2209', 'prompt-tokens': 333, 'completion_tokens': 16, 'total_tokens': 349})\n",
      "(200, {'id': 'chatcmpl-8ngVKteSot0NwpxHiEO0iCVNY94mV', 'object': 'chat.completion', 'created': 1706852150, 'model': 'gpt-4', 'choices': [{'finish_reason': 'length', 'index': 0, 'message': {'role': 'assistant', 'content': \"You're welcome! If you have any more questions or need information on a specific topic, feel free to ask. I\"}}], 'usage': {'prompt_tokens': 333, 'completion_tokens': 24, 'total_tokens': 357}, 'system_fingerprint': 'fp_68a7d165bf'}, {'remaining-requests': '5', 'remaining-tokens': '725', 'prompt-tokens': 333, 'completion_tokens': 24, 'total_tokens': 357})\n",
      "(200, {'id': 'chatcmpl-8ngVJfsiFpQ5CPcWwDHuWjhCa1dol', 'object': 'chat.completion', 'created': 1706852149, 'model': 'gpt-4', 'choices': [{'finish_reason': 'length', 'index': 0, 'message': {'role': 'assistant', 'content': \"You're welcome! If you have any more questions or need assistance with anything else, feel free to reach out. I\"}}], 'usage': {'prompt_tokens': 333, 'completion_tokens': 24, 'total_tokens': 357}, 'system_fingerprint': 'fp_68a7d165bf'}, {'remaining-requests': '9', 'remaining-tokens': '2209', 'prompt-tokens': 333, 'completion_tokens': 24, 'total_tokens': 357})\n",
      "(200, {'id': 'chatcmpl-8ngVK7GyDbWV6I07KW1z778TFEyBj', 'object': 'chat.completion', 'created': 1706852150, 'model': 'gpt-4', 'choices': [{'finish_reason': 'length', 'index': 0, 'message': {'role': 'assistant', 'content': \"You're welcome! If you have any more questions or need further clarification on any topic, feel free to reach out,\"}}], 'usage': {'prompt_tokens': 333, 'completion_tokens': 24, 'total_tokens': 357}, 'system_fingerprint': 'fp_68a7d165bf'}, {'remaining-requests': '7', 'remaining-tokens': '1467', 'prompt-tokens': 333, 'completion_tokens': 24, 'total_tokens': 357})\n",
      "(200, {'id': 'chatcmpl-8ngVKxLdIAn3bhOGVJ4HKnBFpIoBI', 'object': 'chat.completion', 'created': 1706852150, 'model': 'gpt-4', 'choices': [{'finish_reason': 'length', 'index': 0, 'message': {'role': 'assistant', 'content': \"You're welcome! I'm glad to help. If there's anything else you'd like to learn about or need assistance\"}}], 'usage': {'prompt_tokens': 333, 'completion_tokens': 24, 'total_tokens': 357}, 'system_fingerprint': 'fp_68a7d165bf'}, {'remaining-requests': '7', 'remaining-tokens': '1467', 'prompt-tokens': 333, 'completion_tokens': 24, 'total_tokens': 357})\n",
      "(200, {'id': 'chatcmpl-8ngVKuFhz3Oi8yuGEgSX1PXvgKhpI', 'object': 'chat.completion', 'created': 1706852150, 'model': 'gpt-4', 'choices': [{'finish_reason': 'length', 'index': 0, 'message': {'role': 'assistant', 'content': \"You're welcome! If you have any other questions or need further clarification, feel free to ask. I'm here to\"}}], 'usage': {'prompt_tokens': 333, 'completion_tokens': 24, 'total_tokens': 357}, 'system_fingerprint': 'fp_68a7d165bf'}, {'remaining-requests': '8', 'remaining-tokens': '1838', 'prompt-tokens': 333, 'completion_tokens': 24, 'total_tokens': 357})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-01 23:35:54,752 - micro - MainProcess - ERROR    HTTP error occurred: 429 Client Error: Too Many Requests for url: https://ml-workspace-dev-canadaeast-001-aoai.openai.azure.com/openai/deployments/foundational-canadaeast-gpt4/chat/completions?api-version=2023-05-15 (2920182161.py:call_azure_openai_chat_completions_api:35)\n",
      "2024-02-01 23:35:54,769 - micro - MainProcess - ERROR    HTTP error occurred: 429 Client Error: Too Many Requests for url: https://ml-workspace-dev-canadaeast-001-aoai.openai.azure.com/openai/deployments/foundational-canadaeast-gpt4/chat/completions?api-version=2023-05-15 (2920182161.py:call_azure_openai_chat_completions_api:35)\n",
      "2024-02-01 23:35:54,778 - micro - MainProcess - ERROR    HTTP error occurred: 429 Client Error: Too Many Requests for url: https://ml-workspace-dev-canadaeast-001-aoai.openai.azure.com/openai/deployments/foundational-canadaeast-gpt4/chat/completions?api-version=2023-05-15 (2920182161.py:call_azure_openai_chat_completions_api:35)\n",
      "2024-02-01 23:35:54,810 - micro - MainProcess - ERROR    HTTP error occurred: 429 Client Error: Too Many Requests for url: https://ml-workspace-dev-canadaeast-001-aoai.openai.azure.com/openai/deployments/foundational-canadaeast-gpt4/chat/completions?api-version=2023-05-15 (2920182161.py:call_azure_openai_chat_completions_api:35)\n",
      "2024-02-01 23:35:54,817 - micro - MainProcess - ERROR    HTTP error occurred: 429 Client Error: Too Many Requests for url: https://ml-workspace-dev-canadaeast-001-aoai.openai.azure.com/openai/deployments/foundational-canadaeast-gpt4/chat/completions?api-version=2023-05-15 (2920182161.py:call_azure_openai_chat_completions_api:35)\n",
      "2024-02-01 23:35:54,820 - micro - MainProcess - ERROR    HTTP error occurred: 429 Client Error: Too Many Requests for url: https://ml-workspace-dev-canadaeast-001-aoai.openai.azure.com/openai/deployments/foundational-canadaeast-gpt4/chat/completions?api-version=2023-05-15 (2920182161.py:call_azure_openai_chat_completions_api:35)\n",
      "2024-02-01 23:35:54,839 - micro - MainProcess - ERROR    HTTP error occurred: 429 Client Error: Too Many Requests for url: https://ml-workspace-dev-canadaeast-001-aoai.openai.azure.com/openai/deployments/foundational-canadaeast-gpt4/chat/completions?api-version=2023-05-15 (2920182161.py:call_azure_openai_chat_completions_api:35)\n",
      "2024-02-01 23:35:54,841 - micro - MainProcess - ERROR    HTTP error occurred: 429 Client Error: Too Many Requests for url: https://ml-workspace-dev-canadaeast-001-aoai.openai.azure.com/openai/deployments/foundational-canadaeast-gpt4/chat/completions?api-version=2023-05-15 (2920182161.py:call_azure_openai_chat_completions_api:35)\n",
      "2024-02-01 23:35:54,842 - micro - MainProcess - ERROR    HTTP error occurred: 429 Client Error: Too Many Requests for url: https://ml-workspace-dev-canadaeast-001-aoai.openai.azure.com/openai/deployments/foundational-canadaeast-gpt4/chat/completions?api-version=2023-05-15 (2920182161.py:call_azure_openai_chat_completions_api:35)\n",
      "2024-02-01 23:35:54,843 - micro - MainProcess - ERROR    HTTP error occurred: 429 Client Error: Too Many Requests for url: https://ml-workspace-dev-canadaeast-001-aoai.openai.azure.com/openai/deployments/foundational-canadaeast-gpt4/chat/completions?api-version=2023-05-15 (2920182161.py:call_azure_openai_chat_completions_api:35)\n",
      "2024-02-01 23:35:57,235 - micro - MainProcess - ERROR    HTTP error occurred: 429 Client Error: Too Many Requests for url: https://ml-workspace-dev-canadaeast-001-aoai.openai.azure.com/openai/deployments/foundational-canadaeast-gpt4/chat/completions?api-version=2023-05-15 (2920182161.py:call_azure_openai_chat_completions_api:35)\n",
      "2024-02-01 23:35:57,379 - micro - MainProcess - ERROR    HTTP error occurred: 429 Client Error: Too Many Requests for url: https://ml-workspace-dev-canadaeast-001-aoai.openai.azure.com/openai/deployments/foundational-canadaeast-gpt4/chat/completions?api-version=2023-05-15 (2920182161.py:call_azure_openai_chat_completions_api:35)\n",
      "2024-02-01 23:35:57,380 - micro - MainProcess - ERROR    HTTP error occurred: 429 Client Error: Too Many Requests for url: https://ml-workspace-dev-canadaeast-001-aoai.openai.azure.com/openai/deployments/foundational-canadaeast-gpt4/chat/completions?api-version=2023-05-15 (2920182161.py:call_azure_openai_chat_completions_api:35)\n",
      "2024-02-01 23:35:57,423 - micro - MainProcess - ERROR    HTTP error occurred: 429 Client Error: Too Many Requests for url: https://ml-workspace-dev-canadaeast-001-aoai.openai.azure.com/openai/deployments/foundational-canadaeast-gpt4/chat/completions?api-version=2023-05-15 (2920182161.py:call_azure_openai_chat_completions_api:35)\n",
      "2024-02-01 23:35:57,499 - micro - MainProcess - ERROR    HTTP error occurred: 429 Client Error: Too Many Requests for url: https://ml-workspace-dev-canadaeast-001-aoai.openai.azure.com/openai/deployments/foundational-canadaeast-gpt4/chat/completions?api-version=2023-05-15 (2920182161.py:call_azure_openai_chat_completions_api:35)\n",
      "2024-02-01 23:35:57,504 - micro - MainProcess - ERROR    HTTP error occurred: 429 Client Error: Too Many Requests for url: https://ml-workspace-dev-canadaeast-001-aoai.openai.azure.com/openai/deployments/foundational-canadaeast-gpt4/chat/completions?api-version=2023-05-15 (2920182161.py:call_azure_openai_chat_completions_api:35)\n",
      "2024-02-01 23:35:57,507 - micro - MainProcess - ERROR    HTTP error occurred: 429 Client Error: Too Many Requests for url: https://ml-workspace-dev-canadaeast-001-aoai.openai.azure.com/openai/deployments/foundational-canadaeast-gpt4/chat/completions?api-version=2023-05-15 (2920182161.py:call_azure_openai_chat_completions_api:35)\n",
      "2024-02-01 23:35:57,528 - micro - MainProcess - ERROR    HTTP error occurred: 429 Client Error: Too Many Requests for url: https://ml-workspace-dev-canadaeast-001-aoai.openai.azure.com/openai/deployments/foundational-canadaeast-gpt4/chat/completions?api-version=2023-05-15 (2920182161.py:call_azure_openai_chat_completions_api:35)\n",
      "2024-02-01 23:35:57,530 - micro - MainProcess - ERROR    HTTP error occurred: 429 Client Error: Too Many Requests for url: https://ml-workspace-dev-canadaeast-001-aoai.openai.azure.com/openai/deployments/foundational-canadaeast-gpt4/chat/completions?api-version=2023-05-15 (2920182161.py:call_azure_openai_chat_completions_api:35)\n",
      "2024-02-01 23:35:57,535 - micro - MainProcess - ERROR    HTTP error occurred: 429 Client Error: Too Many Requests for url: https://ml-workspace-dev-canadaeast-001-aoai.openai.azure.com/openai/deployments/foundational-canadaeast-gpt4/chat/completions?api-version=2023-05-15 (2920182161.py:call_azure_openai_chat_completions_api:35)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(429, {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-05-15 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}, {})\n",
      "(429, {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-05-15 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}, {})\n",
      "(429, {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-05-15 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}, {})\n",
      "(429, {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-05-15 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}, {})\n",
      "(429, {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-05-15 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}, {})\n",
      "(429, {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-05-15 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}, {})\n",
      "(429, {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-05-15 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}, {})\n",
      "(429, {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-05-15 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}, {})\n",
      "(429, {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-05-15 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}, {})\n",
      "(429, {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-05-15 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}, {})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-01 23:36:01,176 - micro - MainProcess - ERROR    HTTP error occurred: 429 Client Error: Too Many Requests for url: https://ml-workspace-dev-canadaeast-001-aoai.openai.azure.com/openai/deployments/foundational-canadaeast-gpt4/chat/completions?api-version=2023-05-15 (2920182161.py:call_azure_openai_chat_completions_api:35)\n",
      "2024-02-01 23:36:01,202 - micro - MainProcess - ERROR    HTTP error occurred: 429 Client Error: Too Many Requests for url: https://ml-workspace-dev-canadaeast-001-aoai.openai.azure.com/openai/deployments/foundational-canadaeast-gpt4/chat/completions?api-version=2023-05-15 (2920182161.py:call_azure_openai_chat_completions_api:35)\n",
      "2024-02-01 23:36:01,353 - micro - MainProcess - ERROR    HTTP error occurred: 429 Client Error: Too Many Requests for url: https://ml-workspace-dev-canadaeast-001-aoai.openai.azure.com/openai/deployments/foundational-canadaeast-gpt4/chat/completions?api-version=2023-05-15 (2920182161.py:call_azure_openai_chat_completions_api:35)\n",
      "2024-02-01 23:36:01,356 - micro - MainProcess - ERROR    HTTP error occurred: 429 Client Error: Too Many Requests for url: https://ml-workspace-dev-canadaeast-001-aoai.openai.azure.com/openai/deployments/foundational-canadaeast-gpt4/chat/completions?api-version=2023-05-15 (2920182161.py:call_azure_openai_chat_completions_api:35)\n",
      "2024-02-01 23:36:01,356 - micro - MainProcess - ERROR    HTTP error occurred: 429 Client Error: Too Many Requests for url: https://ml-workspace-dev-canadaeast-001-aoai.openai.azure.com/openai/deployments/foundational-canadaeast-gpt4/chat/completions?api-version=2023-05-15 (2920182161.py:call_azure_openai_chat_completions_api:35)\n",
      "2024-02-01 23:36:01,359 - micro - MainProcess - ERROR    HTTP error occurred: 429 Client Error: Too Many Requests for url: https://ml-workspace-dev-canadaeast-001-aoai.openai.azure.com/openai/deployments/foundational-canadaeast-gpt4/chat/completions?api-version=2023-05-15 (2920182161.py:call_azure_openai_chat_completions_api:35)\n",
      "2024-02-01 23:36:01,359 - micro - MainProcess - ERROR    HTTP error occurred: 429 Client Error: Too Many Requests for url: https://ml-workspace-dev-canadaeast-001-aoai.openai.azure.com/openai/deployments/foundational-canadaeast-gpt4/chat/completions?api-version=2023-05-15 (2920182161.py:call_azure_openai_chat_completions_api:35)\n",
      "2024-02-01 23:36:01,361 - micro - MainProcess - ERROR    HTTP error occurred: 429 Client Error: Too Many Requests for url: https://ml-workspace-dev-canadaeast-001-aoai.openai.azure.com/openai/deployments/foundational-canadaeast-gpt4/chat/completions?api-version=2023-05-15 (2920182161.py:call_azure_openai_chat_completions_api:35)\n",
      "2024-02-01 23:36:01,364 - micro - MainProcess - ERROR    HTTP error occurred: 429 Client Error: Too Many Requests for url: https://ml-workspace-dev-canadaeast-001-aoai.openai.azure.com/openai/deployments/foundational-canadaeast-gpt4/chat/completions?api-version=2023-05-15 (2920182161.py:call_azure_openai_chat_completions_api:35)\n",
      "2024-02-01 23:36:01,402 - micro - MainProcess - ERROR    HTTP error occurred: 429 Client Error: Too Many Requests for url: https://ml-workspace-dev-canadaeast-001-aoai.openai.azure.com/openai/deployments/foundational-canadaeast-gpt4/chat/completions?api-version=2023-05-15 (2920182161.py:call_azure_openai_chat_completions_api:35)\n",
      "2024-02-01 23:36:03,421 - micro - MainProcess - ERROR    HTTP error occurred: 429 Client Error: Too Many Requests for url: https://ml-workspace-dev-canadaeast-001-aoai.openai.azure.com/openai/deployments/foundational-canadaeast-gpt4/chat/completions?api-version=2023-05-15 (2920182161.py:call_azure_openai_chat_completions_api:35)\n",
      "2024-02-01 23:36:03,515 - micro - MainProcess - ERROR    HTTP error occurred: 429 Client Error: Too Many Requests for url: https://ml-workspace-dev-canadaeast-001-aoai.openai.azure.com/openai/deployments/foundational-canadaeast-gpt4/chat/completions?api-version=2023-05-15 (2920182161.py:call_azure_openai_chat_completions_api:35)\n",
      "2024-02-01 23:36:03,950 - micro - MainProcess - ERROR    HTTP error occurred: 429 Client Error: Too Many Requests for url: https://ml-workspace-dev-canadaeast-001-aoai.openai.azure.com/openai/deployments/foundational-canadaeast-gpt4/chat/completions?api-version=2023-05-15 (2920182161.py:call_azure_openai_chat_completions_api:35)\n",
      "2024-02-01 23:36:03,959 - micro - MainProcess - ERROR    HTTP error occurred: 429 Client Error: Too Many Requests for url: https://ml-workspace-dev-canadaeast-001-aoai.openai.azure.com/openai/deployments/foundational-canadaeast-gpt4/chat/completions?api-version=2023-05-15 (2920182161.py:call_azure_openai_chat_completions_api:35)\n",
      "2024-02-01 23:36:03,998 - micro - MainProcess - ERROR    HTTP error occurred: 429 Client Error: Too Many Requests for url: https://ml-workspace-dev-canadaeast-001-aoai.openai.azure.com/openai/deployments/foundational-canadaeast-gpt4/chat/completions?api-version=2023-05-15 (2920182161.py:call_azure_openai_chat_completions_api:35)\n",
      "2024-02-01 23:36:04,004 - micro - MainProcess - ERROR    HTTP error occurred: 429 Client Error: Too Many Requests for url: https://ml-workspace-dev-canadaeast-001-aoai.openai.azure.com/openai/deployments/foundational-canadaeast-gpt4/chat/completions?api-version=2023-05-15 (2920182161.py:call_azure_openai_chat_completions_api:35)\n",
      "2024-02-01 23:36:04,006 - micro - MainProcess - ERROR    HTTP error occurred: 429 Client Error: Too Many Requests for url: https://ml-workspace-dev-canadaeast-001-aoai.openai.azure.com/openai/deployments/foundational-canadaeast-gpt4/chat/completions?api-version=2023-05-15 (2920182161.py:call_azure_openai_chat_completions_api:35)\n",
      "2024-02-01 23:36:04,011 - micro - MainProcess - ERROR    HTTP error occurred: 429 Client Error: Too Many Requests for url: https://ml-workspace-dev-canadaeast-001-aoai.openai.azure.com/openai/deployments/foundational-canadaeast-gpt4/chat/completions?api-version=2023-05-15 (2920182161.py:call_azure_openai_chat_completions_api:35)\n",
      "2024-02-01 23:36:04,012 - micro - MainProcess - ERROR    HTTP error occurred: 429 Client Error: Too Many Requests for url: https://ml-workspace-dev-canadaeast-001-aoai.openai.azure.com/openai/deployments/foundational-canadaeast-gpt4/chat/completions?api-version=2023-05-15 (2920182161.py:call_azure_openai_chat_completions_api:35)\n",
      "2024-02-01 23:36:04,013 - micro - MainProcess - ERROR    HTTP error occurred: 429 Client Error: Too Many Requests for url: https://ml-workspace-dev-canadaeast-001-aoai.openai.azure.com/openai/deployments/foundational-canadaeast-gpt4/chat/completions?api-version=2023-05-15 (2920182161.py:call_azure_openai_chat_completions_api:35)\n",
      "2024-02-01 23:36:04,982 - micro - MainProcess - ERROR    HTTP error occurred: 429 Client Error: Too Many Requests for url: https://ml-workspace-dev-canadaeast-001-aoai.openai.azure.com/openai/deployments/foundational-canadaeast-gpt4/chat/completions?api-version=2023-05-15 (2920182161.py:call_azure_openai_chat_completions_api:35)\n",
      "2024-02-01 23:36:05,135 - micro - MainProcess - ERROR    HTTP error occurred: 429 Client Error: Too Many Requests for url: https://ml-workspace-dev-canadaeast-001-aoai.openai.azure.com/openai/deployments/foundational-canadaeast-gpt4/chat/completions?api-version=2023-05-15 (2920182161.py:call_azure_openai_chat_completions_api:35)\n"
     ]
    },
    {
     "ename": "CancelledError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mCancelledError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[54], line 27\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# Run the main function\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m):\n\u001b[1;32m---> 27\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m main()\n\u001b[0;32m     28\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m1\u001b[39m)\n",
      "Cell \u001b[1;32mIn[54], line 20\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m):\n\u001b[0;32m     18\u001b[0m     tasks\u001b[38;5;241m.\u001b[39mappend(loop\u001b[38;5;241m.\u001b[39mrun_in_executor(executor, call_api))\n\u001b[1;32m---> 20\u001b[0m responses \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mgather(\u001b[38;5;241m*\u001b[39mtasks)\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m response \u001b[38;5;129;01min\u001b[39;00m responses:\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;28mprint\u001b[39m(response)\n",
      "\u001b[1;31mCancelledError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "def call_api():\n",
    "    status_code, response, rate_limit_info = call_azure_openai_chat_completions_api_with_pre_check(\n",
    "        deployment_id=azure_openai_client.chat_model_name,\n",
    "        method=\"post\",\n",
    "        body=body,\n",
    "        api_version=\"2023-05-15\",\n",
    "    )\n",
    "    return status_code, response, rate_limit_info\n",
    "\n",
    "async def main():\n",
    "    with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "        loop = asyncio.get_event_loop()\n",
    "        tasks = []\n",
    "        for _ in range(10):\n",
    "            tasks.append(loop.run_in_executor(executor, call_api))\n",
    "\n",
    "        responses = await asyncio.gather(*tasks)\n",
    "\n",
    "        for response in responses:\n",
    "            print(response)\n",
    "\n",
    "# Run the main function\n",
    "for _ in range(10):\n",
    "    await main()\n",
    "    time.sleep(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vector-indexing-azureaisearch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
