{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“š Prerequisites\n",
    "\n",
    "Ensure that your Azure Services are properly set up, your Conda environment is created, and your environment variables are configured as per the instructions in the [SETTINGS.md](SETTINGS.md) file.\n",
    "\n",
    "## ðŸ“‹ Table of Contents\n",
    "\n",
    "This notebook assists in creating an Azure AI Search Index, covering the following sections:\n",
    "\n",
    "1. [**Define Field Types**](#define-field-types): Outlines the process of defining the structure and behavior of an index using various field types.\n",
    "\n",
    "2. [**Configuring Vector Search**](#configuring-vector-search): Discusses the setup of algorithms and profiles for handling vector-based queries.\n",
    "\n",
    "3. [**Configuring Semantic Search**](#configuring-semantic-search): Explores how to enhance search capabilities by leveraging advanced AI models.\n",
    "\n",
    "4. [**Create or Update Index**](#create-or-update-index): Details the steps to create a new index or update an existing one.\n",
    "\n",
    "For additional information, refer to the following resources:\n",
    "- [Azure AI Search Documentation](https://learn.microsoft.com/en-us/azure/search/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory changed to C:\\Users\\pablosal\\Desktop\\gbbai-azure-aoai-faq\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Define the target directory\n",
    "target_directory = r\"C:\\Users\\pablosal\\Desktop\\gbbai-azure-aoai-faq\"  # change your directory here\n",
    "\n",
    "# Check if the directory exists\n",
    "if os.path.exists(target_directory):\n",
    "    # Change the current working directory\n",
    "    os.chdir(target_directory)\n",
    "    print(f\"Directory changed to {os.getcwd()}\")\n",
    "else:\n",
    "    print(f\"Directory {target_directory} does not exist.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "from utils.ml_logging import get_logger\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "# Set up logger\n",
    "logger = get_logger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.aoai.azure_openai import AzureOpenAIManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import logging\n",
    "import traceback\n",
    "\n",
    "# Setup logger\n",
    "logger = logging.getLogger(__name__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usage\n",
    "# Create an instance of the client\n",
    "azure_openai_client = AzureOpenAIManager()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Optional\n",
    "from requests import Response\n",
    "\n",
    "def call_azure_openai_chat_completions_api(deployment_id: str, \n",
    "                                           method: str, \n",
    "                                           body: dict = None, api_version: str = \"2023-11-01\"):\n",
    "    \"\"\"\n",
    "    Calls the Azure OpenAI API with the given parameters.\n",
    "\n",
    "    :param deployment_id: The ID of the deployment to access.\n",
    "    :param method: The HTTP method to use (\"get\" or \"post\").\n",
    "    :param body: The body of the request for \"post\" method. Defaults to None.\n",
    "    :param api_version: The API version to use. Defaults to \"2023-11-01\".\n",
    "\n",
    "    :return: The status code and response from the API call, along with rate limit headers.\n",
    "    \"\"\"\n",
    "    if method.lower() not in [\"get\", \"post\"]:\n",
    "        logger.error(\"Invalid HTTP method. Expected 'get' or 'post'.\")\n",
    "        return None, None, {}\n",
    "\n",
    "    url = f\"{azure_openai_client.azure_endpoint}/openai/deployments/{deployment_id}/chat/completions?api-version={api_version}\"\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"api-key\": azure_openai_client.api_key\n",
    "    }\n",
    "\n",
    "    with requests.Session() as session:\n",
    "        session.headers.update(headers)\n",
    "\n",
    "        try:\n",
    "            if method.lower() == \"get\":\n",
    "                response = session.get(url)\n",
    "            else:  # method.lower() == \"post\"\n",
    "                response = session.post(url, json=body)\n",
    "            response.raise_for_status()  # Raises HTTPError for bad responses\n",
    "        except requests.HTTPError as http_err:\n",
    "            logger.error(f\"HTTP error occurred: {http_err}\")\n",
    "            return response.status_code, http_err.response.json(), {}\n",
    "        except Exception as err:\n",
    "            logger.error(f\"An error occurred: {err}\")\n",
    "            return None, None, {}\n",
    "\n",
    "    # Extract rate limit headers and usage details\n",
    "    rate_limit_headers = extract_rate_limit_and_usage_info(response)\n",
    "    return response.status_code, response.json(), rate_limit_headers\n",
    "\n",
    "def extract_rate_limit_and_usage_info(response: Response) -> Dict[str, Optional[int]]:\n",
    "    \"\"\"\n",
    "    Extracts rate limiting information from the Azure Open API response headers and usage information from the payload.\n",
    "\n",
    "    :param response: The response object returned by a requests call.\n",
    "    :return: A dictionary containing the remaining requests, remaining tokens, and usage information \n",
    "             including prompt tokens, completion tokens, and total tokens.\n",
    "    \"\"\"\n",
    "    headers = response.headers\n",
    "    usage = response.json().get('usage', {})\n",
    "    return {\n",
    "        'remaining-requests': headers.get('x-ratelimit-remaining-requests'),\n",
    "        'remaining-tokens': headers.get('x-ratelimit-remaining-tokens'),\n",
    "        'prompt-tokens': usage.get('prompt_tokens'),\n",
    "        'completion_tokens': usage.get('completion_tokens'),\n",
    "        'total_tokens': usage.get('total_tokens'),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'foundational-canadaeast-gpt4'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getenv(\"AZURE_AOAI_CHAT_MODEL_DEPLOYMENT_ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'foundational-canadaeast-gpt4'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "azure_openai_client.chat_model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status Code: 200\n",
      "Response: {'id': 'chatcmpl-8l8uTP8PSUS1iQFgRhpD0lxSC5JPz', 'object': 'chat.completion', 'created': 1706246357, 'model': 'gpt-4', 'choices': [{'finish_reason': 'stop', 'index': 0, 'message': {'role': 'assistant', 'content': \"You're welcome! If you have any more questions or need further information on any topic, don't hesitate to ask. I'm here to help!\"}}], 'usage': {'prompt_tokens': 333, 'completion_tokens': 30, 'total_tokens': 363}, 'system_fingerprint': 'fp_6d044fb900'}\n",
      "Rate Limit Info: {'remaining-requests': '9', 'remaining-tokens': '9013', 'prompt-tokens': 333, 'completion_tokens': 30, 'total_tokens': 363}\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "body = {\n",
    "    \"messages\": [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Does Azure OpenAI support customer managed keys?\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"Yes, customer managed keys are supported by Azure OpenAI.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Do other Azure AI services support this too?\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"Yes, other Azure AI services also support customer managed keys.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Can you tell me more about these services?\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"Sure, Azure AI services include Azure Cognitive Services, Azure Machine Learning, and more.\"},\n",
    "        {\"role\": \"user\", \"content\": \"What is Azure Cognitive Services?\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"Azure Cognitive Services is a collection of APIs and services for building intelligent applications.\"},\n",
    "        {\"role\": \"user\", \"content\": \"What is Azure Machine Learning?\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"Azure Machine Learning is a cloud-based service for building, training, and deploying machine learning models.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Thank you for the information.\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"You're welcome! If you have any other questions, feel free to ask.\"},\n",
    "        {\"role\": \"user\", \"content\": \"What other services does Azure offer?\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"Azure offers a wide range of services including computing, analytics, storage, and networking.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Can you tell me more about Azure's computing services?\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"Azure's computing services include virtual machines, container services, and serverless computing.\"},\n",
    "        {\"role\": \"user\", \"content\": \"What is serverless computing?\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"Serverless computing is a cloud computing model where the cloud provider automatically manages the provisioning and scaling of servers.\"},\n",
    "        {\"role\": \"user\", \"content\": \"That's interesting. Thank you for the information.\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"You're welcome! If you have any other questions, feel free to ask.\"},\n",
    "     ]\n",
    "    }\n",
    "# ,\n",
    "#     \"max_tokens\": 150,\n",
    "#     \"n\": 1,\n",
    "#     \"stream\": True,\n",
    "\n",
    "import time\n",
    "\n",
    "status_code, response, rate_limit_info = call_azure_openai_chat_completions_api(\n",
    "    deployment_id=azure_openai_client.completion_model_name,\n",
    "    method='post',\n",
    "    body=body,\n",
    "    api_version='2023-05-15'\n",
    ")\n",
    "\n",
    "# Print the status code, response, and rate limit info\n",
    "print(\"Status Code:\", status_code)\n",
    "print(\"Response:\", response)\n",
    "print(\"Rate Limit Info:\", rate_limit_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HELLO ------------------\n",
      "{'Cache-Control': 'no-cache, must-revalidate', 'Transfer-Encoding': 'chunked', 'Content-Type': 'text/event-stream', 'access-control-allow-origin': '*', 'apim-request-id': 'ed5e43ca-d161-4eab-9fb9-c9b8110a958b', 'Strict-Transport-Security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'x-ms-region': 'Canada East', 'x-ratelimit-remaining-requests': '9', 'x-ratelimit-remaining-tokens': '9006', 'x-accel-buffering': 'no', 'x-request-id': 'e959c574-57a3-40eb-9c03-10dcf182de9c', 'x-ms-client-request-id': 'ed5e43ca-d161-4eab-9fb9-c9b8110a958b', 'azureml-model-session': 'd008-20240109104201', 'Date': 'Thu, 25 Jan 2024 06:02:24 GMT'}\n",
      "HELLO ------------------\n"
     ]
    },
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\pablosal\\AppData\\Local\\anaconda3\\envs\\aoai-faq\\lib\\site-packages\\requests\\models.py:971\u001b[0m, in \u001b[0;36mResponse.json\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    970\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 971\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m complexjson\u001b[38;5;241m.\u001b[39mloads(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtext, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    972\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m JSONDecodeError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    973\u001b[0m     \u001b[38;5;66;03m# Catch JSON-related errors and raise as requests.JSONDecodeError\u001b[39;00m\n\u001b[0;32m    974\u001b[0m     \u001b[38;5;66;03m# This aliases json.JSONDecodeError and simplejson.JSONDecodeError\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\pablosal\\AppData\\Local\\anaconda3\\envs\\aoai-faq\\lib\\json\\__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[1;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[1;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\pablosal\\AppData\\Local\\anaconda3\\envs\\aoai-faq\\lib\\json\\decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[1;34m(self, s, _w)\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;124;03mcontaining a JSON document).\u001b[39;00m\n\u001b[0;32m    335\u001b[0m \n\u001b[0;32m    336\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 337\u001b[0m obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    338\u001b[0m end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n",
      "File \u001b[1;32mc:\\Users\\pablosal\\AppData\\Local\\anaconda3\\envs\\aoai-faq\\lib\\json\\decoder.py:355\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[1;34m(self, s, idx)\u001b[0m\n\u001b[0;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m--> 355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting value\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, err\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    356\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m status_code, response, rate_limit_info \u001b[38;5;241m=\u001b[39m \u001b[43mcall_azure_openai_chat_completions_api\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdeployment_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mazure_openai_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletion_model_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpost\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43mapi_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m2023-05-15\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[12], line 58\u001b[0m, in \u001b[0;36mcall_azure_openai_chat_completions_api\u001b[1;34m(deployment_id, method, body, api_version)\u001b[0m\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHELLO ------------------\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     49\u001b[0m     rate_limit_headers \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     50\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlimit-requests\u001b[39m\u001b[38;5;124m'\u001b[39m: response\u001b[38;5;241m.\u001b[39mheaders\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx-ratelimit-limit-requests\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[0;32m     51\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlimit-tokens\u001b[39m\u001b[38;5;124m'\u001b[39m: response\u001b[38;5;241m.\u001b[39mheaders\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx-ratelimit-limit-tokens\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     55\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreset-tokens\u001b[39m\u001b[38;5;124m'\u001b[39m: response\u001b[38;5;241m.\u001b[39mheaders\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx-ratelimit-reset-tokens\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     56\u001b[0m     }\n\u001b[1;32m---> 58\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;28;01mif\u001b[39;00m response \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m response \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, rate_limit_headers\n",
      "File \u001b[1;32mc:\\Users\\pablosal\\AppData\\Local\\anaconda3\\envs\\aoai-faq\\lib\\site-packages\\requests\\models.py:975\u001b[0m, in \u001b[0;36mResponse.json\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    971\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m complexjson\u001b[38;5;241m.\u001b[39mloads(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtext, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    972\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m JSONDecodeError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    973\u001b[0m     \u001b[38;5;66;03m# Catch JSON-related errors and raise as requests.JSONDecodeError\u001b[39;00m\n\u001b[0;32m    974\u001b[0m     \u001b[38;5;66;03m# This aliases json.JSONDecodeError and simplejson.JSONDecodeError\u001b[39;00m\n\u001b[1;32m--> 975\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m RequestsJSONDecodeError(e\u001b[38;5;241m.\u001b[39mmsg, e\u001b[38;5;241m.\u001b[39mdoc, e\u001b[38;5;241m.\u001b[39mpos)\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "status_code, response, rate_limit_info = call_azure_openai_chat_completions_api(\n",
    "        deployment_id=azure_openai_client.completion_model_name,\n",
    "        method='post',\n",
    "        body=body,\n",
    "        api_version='2023-05-15'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'limit-requests': None,\n",
       " 'limit-tokens': None,\n",
       " 'remaining-requests': '9',\n",
       " 'remaining-tokens': '9013',\n",
       " 'reset-requests': None,\n",
       " 'reset-tokens': None}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rate_limit_info"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vector-indexing-azureaisearch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
